[2024-12-28T18:13:59.475+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:13:59.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:13:59.479+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:13:59.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:13:59.854+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:13:59.840+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:13:59.857+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:13:59.907+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:13:59.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:13:59.924+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:13:59.924+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:13:59.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.482 seconds
[2024-12-28T18:14:30.115+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:14:30.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:14:30.117+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:14:30.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:14:30.269+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:14:30.268+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:14:30.271+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:14:30.290+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:14:30.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:14:30.301+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:14:30.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:14:30.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T18:15:00.461+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:00.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:15:00.470+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:00.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:00.622+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:00.621+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:15:00.624+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:00.644+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:00.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:15:00.655+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:00.655+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:15:00.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.215 seconds
[2024-12-28T18:15:30.811+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:30.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:15:30.814+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:30.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:30.975+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:30.975+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:15:30.977+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:15:31.001+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:31.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:15:31.018+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:15:31.017+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:15:31.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.374 seconds
[2024-12-28T18:16:01.335+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:01.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:16:01.338+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:01.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:01.485+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:01.484+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:16:01.487+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:01.511+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:01.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:16:01.671+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:01.671+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:16:01.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.355 seconds
[2024-12-28T18:16:31.835+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:31.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:16:31.837+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:31.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:31.985+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:31.984+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:16:31.987+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:16:32.141+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:32.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:16:32.152+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:16:32.152+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:16:32.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.335 seconds
[2024-12-28T18:17:02.312+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:02.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:17:02.315+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:02.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:02.556+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:02.554+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:17:02.558+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:02.750+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:02.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:17:02.766+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:02.766+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:17:02.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.479 seconds
[2024-12-28T18:17:32.931+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:32.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:17:32.934+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:32.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:33.203+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:33.202+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:17:33.205+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:17:33.226+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:33.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:17:33.239+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:17:33.239+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:17:33.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.329 seconds
[2024-12-28T18:18:03.408+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:03.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:18:03.411+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:03.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:03.715+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:03.714+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:18:03.716+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:03.734+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:03.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:18:03.744+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:03.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:18:03.759+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.356 seconds
[2024-12-28T18:18:33.906+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:33.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:18:33.908+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:33.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:34.069+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:34.068+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:18:34.071+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:18:34.095+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:34.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:18:34.111+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:18:34.111+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:18:34.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2024-12-28T18:19:04.280+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:04.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:19:04.283+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:04.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:04.443+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:04.442+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:19:04.445+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:04.465+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:04.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:19:04.477+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:04.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:19:04.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T18:19:34.652+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:34.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:19:34.655+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:34.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:34.838+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:34.837+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:19:34.839+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:19:34.859+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:34.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:19:34.871+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:19:34.871+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:19:34.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2024-12-28T18:20:05.037+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:05.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:20:05.040+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:05.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:05.198+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:05.197+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:20:05.199+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:05.219+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:05.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:20:05.230+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:05.230+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:20:05.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T18:20:35.395+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:35.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:20:35.398+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:35.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:35.551+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:35.550+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:20:35.552+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:20:35.576+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:35.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:20:35.588+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:20:35.588+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:20:35.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T18:21:05.750+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:05.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:21:05.752+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:05.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:05.904+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:05.903+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:21:05.906+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:05.928+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:05.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:21:05.941+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:05.941+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:21:05.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T18:21:36.099+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:36.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:21:36.101+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:36.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:36.272+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:36.271+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:21:36.274+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:21:36.298+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:36.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:21:36.313+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:21:36.313+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:21:36.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T18:22:06.473+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:06.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:22:06.476+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:06.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:06.640+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:06.639+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:22:06.642+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:06.666+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:06.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:22:06.679+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:06.679+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:22:06.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T18:22:36.834+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:36.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:22:36.837+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:36.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:36.989+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:36.988+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:22:36.991+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:22:37.015+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:37.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:22:37.030+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:22:37.030+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:22:37.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T18:23:07.202+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:07.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:23:07.205+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:07.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:07.359+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:07.358+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:23:07.361+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:07.385+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:07.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:23:07.400+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:07.400+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:23:07.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T18:23:37.580+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:37.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:23:37.583+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:37.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:37.741+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:37.740+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:23:37.743+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:23:37.763+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:37.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:23:37.775+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:23:37.775+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:23:37.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T18:24:07.943+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:07.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:24:07.946+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:07.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:08.099+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:08.098+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:24:08.100+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:08.124+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:08.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:24:08.141+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:08.140+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:24:08.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T18:24:38.303+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:38.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:24:38.306+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:38.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:38.457+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:38.457+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:24:38.459+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:24:38.484+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:38.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:24:38.499+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:24:38.499+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:24:38.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T18:25:08.667+0000] {processor.py:186} INFO - Started process (PID=229) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:08.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:25:08.671+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:08.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:08.879+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:08.878+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:25:08.881+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:08.906+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:08.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:25:08.921+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:08.921+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:25:08.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.276 seconds
[2024-12-28T18:25:39.095+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:39.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:25:39.099+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:39.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:39.419+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:39.418+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:25:39.421+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:25:39.447+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:39.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:25:39.464+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:25:39.463+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:25:39.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.401 seconds
[2024-12-28T18:26:09.674+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:09.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:26:09.677+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:09.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:09.901+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:09.900+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:26:09.904+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:09.931+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:09.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:26:09.947+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:09.947+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:26:09.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.297 seconds
[2024-12-28T18:26:40.111+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:40.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:26:40.113+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:40.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:40.328+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:40.326+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:26:40.330+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:26:40.356+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:40.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:26:40.374+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:26:40.374+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:26:40.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.287 seconds
[2024-12-28T18:27:10.543+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:10.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:27:10.545+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:10.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:10.715+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:10.714+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:27:10.717+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:10.741+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:10.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:27:10.757+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:10.757+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:27:10.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T18:27:40.922+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:40.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:27:40.925+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:40.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:41.116+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:41.115+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:27:41.119+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:27:41.146+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:41.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:27:41.162+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:27:41.162+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:27:41.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.267 seconds
[2024-12-28T18:28:11.334+0000] {processor.py:186} INFO - Started process (PID=289) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:11.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:28:11.338+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:11.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:11.546+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:11.545+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:28:11.549+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:11.574+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:11.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:28:11.590+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:11.590+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:28:11.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.280 seconds
[2024-12-28T18:28:41.756+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:41.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:28:41.758+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:41.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:41.936+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:41.935+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:28:41.938+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:28:41.958+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:41.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:28:41.970+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:28:41.969+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:28:41.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T18:29:12.144+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:12.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:29:12.147+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:12.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:12.300+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:12.299+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:29:12.302+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:12.326+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:12.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:29:12.341+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:12.341+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:29:12.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T18:29:42.504+0000] {processor.py:186} INFO - Started process (PID=317) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:42.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:29:42.507+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:42.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:42.676+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:42.675+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:29:42.678+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:29:42.702+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:42.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:29:42.719+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:29:42.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:29:42.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T18:30:12.887+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:12.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:30:12.894+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:12.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:13.058+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:13.057+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:30:13.059+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:13.084+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:13.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:30:13.096+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:13.096+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:30:13.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T18:30:43.255+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:43.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:30:43.257+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:43.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:43.407+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:43.406+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:30:43.408+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:30:43.433+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:43.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:30:43.448+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:30:43.448+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:30:43.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T18:31:13.615+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:13.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:31:13.619+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:13.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:13.791+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:13.790+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:31:13.793+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:13.817+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:13.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:31:13.832+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:13.832+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:31:13.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2024-12-28T18:31:43.999+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:44.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:31:44.002+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:44.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:44.168+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:44.167+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:31:44.170+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:31:44.194+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:44.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:31:44.209+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:31:44.209+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:31:44.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T18:32:14.371+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:14.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:32:14.378+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:14.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:14.537+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:14.536+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:32:14.539+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:14.559+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:14.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:32:14.572+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:14.571+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:32:14.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T18:32:44.733+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:44.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:32:44.736+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:44.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:44.894+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:44.894+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:32:44.896+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:32:44.921+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:44.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:32:44.937+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:32:44.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:32:44.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2024-12-28T18:33:15.104+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:15.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:33:15.107+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:15.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:15.279+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:15.278+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:33:15.281+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:15.302+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:15.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:33:15.314+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:15.314+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:33:15.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T18:33:45.473+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:45.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:33:45.476+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:45.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:45.634+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:45.633+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:33:45.636+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:33:45.661+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:45.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:33:45.674+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:33:45.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:33:45.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2024-12-28T18:34:15.862+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:15.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:34:15.865+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:15.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:16.071+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:16.070+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:34:16.073+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:16.097+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:16.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:34:16.113+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:16.112+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:34:16.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.273 seconds
[2024-12-28T18:34:46.279+0000] {processor.py:186} INFO - Started process (PID=407) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:46.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:34:46.282+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:46.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:46.455+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:46.454+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:34:46.457+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:34:46.478+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:46.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:34:46.490+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:34:46.490+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:34:46.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T18:35:16.649+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:16.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:35:16.652+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:16.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:16.825+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:16.824+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:35:16.827+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:16.847+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:16.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:35:16.861+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:16.861+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:35:16.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T18:35:47.024+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:47.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:35:47.026+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:47.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:47.185+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:47.184+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:35:47.187+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:35:47.211+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:47.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:35:47.227+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:35:47.227+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:35:47.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T18:36:17.395+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:17.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:36:17.398+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:17.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:17.558+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:17.557+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:36:17.559+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:17.579+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:17.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:36:17.591+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:17.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:36:17.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T18:36:47.759+0000] {processor.py:186} INFO - Started process (PID=443) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:47.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:36:47.762+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:47.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:47.933+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:47.932+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:36:47.935+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:36:47.959+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:47.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:36:47.974+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:36:47.974+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:36:47.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T18:37:18.144+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:18.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:37:18.147+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:18.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:18.299+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:18.298+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:37:18.301+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:18.325+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:18.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:37:18.341+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:18.341+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:37:18.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T18:37:48.508+0000] {processor.py:186} INFO - Started process (PID=461) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:48.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:37:48.510+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:48.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:48.669+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:48.668+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:37:48.671+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:37:48.695+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:48.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:37:48.712+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:37:48.712+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:37:48.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T18:38:18.876+0000] {processor.py:186} INFO - Started process (PID=470) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:18.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:38:18.879+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:18.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:19.032+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:19.031+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:38:19.034+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:19.058+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:19.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:38:19.075+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:19.075+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:38:19.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:38:49.235+0000] {processor.py:186} INFO - Started process (PID=479) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:49.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:38:49.238+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:49.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:49.408+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:49.407+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:38:49.410+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:38:49.435+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:49.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:38:49.450+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:38:49.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:38:49.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T18:39:19.624+0000] {processor.py:186} INFO - Started process (PID=488) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:19.625+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:39:19.627+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:19.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:19.778+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:19.777+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:39:19.779+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:19.799+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:19.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:39:19.811+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:19.811+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:39:19.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T18:39:49.975+0000] {processor.py:186} INFO - Started process (PID=497) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:49.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:39:49.978+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:49.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:50.140+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:50.140+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:39:50.142+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:39:50.166+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:50.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:39:50.178+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:39:50.178+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:39:50.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T18:40:20.344+0000] {processor.py:186} INFO - Started process (PID=506) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:20.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:40:20.348+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:20.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:20.507+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:20.506+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:40:20.508+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:20.533+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:20.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:40:20.544+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:20.544+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:40:20.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:40:50.724+0000] {processor.py:186} INFO - Started process (PID=515) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:50.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:40:50.728+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:50.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:51.012+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:51.011+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:40:51.015+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:40:51.042+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:51.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:40:51.062+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:40:51.062+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:40:51.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.379 seconds
[2024-12-28T18:41:21.252+0000] {processor.py:186} INFO - Started process (PID=524) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:21.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:41:21.255+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:21.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:21.416+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:21.415+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:41:21.418+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:21.443+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:21.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:41:21.456+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:21.456+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:41:21.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T18:41:51.620+0000] {processor.py:186} INFO - Started process (PID=533) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:51.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:41:51.623+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:51.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:51.783+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:51.782+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:41:51.785+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:41:51.809+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:51.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:41:51.824+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:41:51.824+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:41:51.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2024-12-28T18:42:21.995+0000] {processor.py:186} INFO - Started process (PID=542) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:21.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:42:21.998+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:21.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:22.148+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:22.147+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:42:22.150+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:22.174+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:22.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:42:22.187+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:22.187+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:42:22.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T18:42:52.349+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:52.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:42:52.352+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:52.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:52.524+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:52.523+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:42:52.526+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:42:52.550+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:52.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:42:52.566+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:42:52.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:42:52.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2024-12-28T18:43:22.728+0000] {processor.py:186} INFO - Started process (PID=560) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:22.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:43:22.732+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:22.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:22.883+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:22.882+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:43:22.885+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:22.909+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:22.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:43:22.925+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:22.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:43:22.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T18:43:53.083+0000] {processor.py:186} INFO - Started process (PID=569) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:53.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:43:53.086+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:53.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:53.239+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:53.238+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:43:53.241+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:43:53.265+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:53.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:43:53.282+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:43:53.281+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:43:53.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T18:44:23.459+0000] {processor.py:186} INFO - Started process (PID=578) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:23.461+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:44:23.463+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:23.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:23.626+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:23.625+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:44:23.628+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:23.648+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:23.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:44:23.660+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:23.660+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:44:23.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:44:53.827+0000] {processor.py:186} INFO - Started process (PID=588) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:53.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:44:53.830+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:53.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:54.011+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:54.010+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:44:54.013+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:44:54.037+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:54.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:44:54.053+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:44:54.053+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:44:54.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.249 seconds
[2024-12-28T18:45:24.225+0000] {processor.py:186} INFO - Started process (PID=597) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:24.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:45:24.228+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:24.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:24.402+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:24.402+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:45:24.404+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:24.429+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:24.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:45:24.444+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:24.444+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:45:24.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.241 seconds
[2024-12-28T18:45:54.607+0000] {processor.py:186} INFO - Started process (PID=606) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:54.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:45:54.610+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:54.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:54.765+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:54.764+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:45:54.767+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:45:54.791+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:54.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:45:54.807+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:45:54.807+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:45:54.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.223 seconds
[2024-12-28T18:46:24.971+0000] {processor.py:186} INFO - Started process (PID=615) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:24.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:46:24.974+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:24.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:25.125+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:25.124+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:46:25.127+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:25.151+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:25.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:46:25.167+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:25.167+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:46:25.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T18:46:55.334+0000] {processor.py:186} INFO - Started process (PID=624) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:55.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:46:55.337+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:55.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:55.516+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:55.515+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:46:55.518+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:46:55.539+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:55.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:46:55.551+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:46:55.550+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:46:55.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2024-12-28T18:47:25.720+0000] {processor.py:186} INFO - Started process (PID=633) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:25.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:47:25.722+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:25.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:25.897+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:25.896+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:47:25.899+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:25.919+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:25.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:47:25.931+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:25.931+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:47:25.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T18:47:56.092+0000] {processor.py:186} INFO - Started process (PID=642) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:56.093+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:47:56.095+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:56.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:56.270+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:56.269+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:47:56.272+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:47:56.292+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:56.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:47:56.304+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:47:56.303+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:47:56.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T18:48:26.469+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:26.470+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:48:26.473+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:26.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:26.673+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:26.672+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:48:26.676+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:26.702+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:26.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:48:26.719+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:26.718+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:48:26.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.273 seconds
[2024-12-28T18:48:56.884+0000] {processor.py:186} INFO - Started process (PID=660) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:56.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:48:56.888+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:56.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:57.040+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:57.039+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:48:57.042+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:48:57.066+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:57.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:48:57.083+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:48:57.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:48:57.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:49:27.254+0000] {processor.py:186} INFO - Started process (PID=669) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:27.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:49:27.257+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:27.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:27.409+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:27.408+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:49:27.410+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:27.431+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:27.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:49:27.443+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:27.442+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:49:27.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T18:49:57.609+0000] {processor.py:186} INFO - Started process (PID=678) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:57.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:49:57.612+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:57.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:57.764+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:57.763+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:49:57.765+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:49:57.790+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:57.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:49:57.802+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:49:57.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:49:57.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T18:50:27.972+0000] {processor.py:186} INFO - Started process (PID=687) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:27.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:50:27.978+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:27.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:28.150+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:28.149+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:50:28.152+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:28.172+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:28.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:50:28.183+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:28.183+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:50:28.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T18:50:58.350+0000] {processor.py:186} INFO - Started process (PID=696) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:58.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:50:58.352+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:58.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:58.509+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:58.508+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:50:58.512+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:50:58.532+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:58.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:50:58.544+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:50:58.544+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:50:58.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T18:51:28.704+0000] {processor.py:186} INFO - Started process (PID=705) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:28.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:51:28.707+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:28.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:28.880+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:28.879+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:51:28.882+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:28.903+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:28.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:51:28.916+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:28.915+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:51:28.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2024-12-28T18:51:59.080+0000] {processor.py:186} INFO - Started process (PID=715) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:59.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:51:59.083+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:59.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:59.239+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:59.238+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:51:59.241+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:51:59.265+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:59.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:51:59.281+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:51:59.281+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:51:59.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T18:52:29.450+0000] {processor.py:186} INFO - Started process (PID=724) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:52:29.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:52:29.454+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:52:29.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:52:29.633+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:52:29.632+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:52:29.635+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:52:29.656+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:52:29.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:52:29.668+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:52:29.668+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:52:29.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2024-12-28T18:52:59.836+0000] {processor.py:186} INFO - Started process (PID=733) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:52:59.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:52:59.839+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:52:59.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:53:00.013+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:00.012+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:53:00.015+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:53:00.035+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:00.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:53:00.047+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:00.046+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:53:00.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T18:53:30.208+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:53:30.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:53:30.212+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:30.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:53:30.365+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:30.364+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:53:30.367+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:53:30.392+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:30.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:53:30.408+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:53:30.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:53:30.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T18:54:00.576+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:00.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:54:00.579+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:00.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:00.730+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:00.729+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:54:00.732+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:00.756+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:00.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:54:00.772+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:00.772+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:54:00.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T18:54:30.947+0000] {processor.py:186} INFO - Started process (PID=760) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:30.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:54:30.950+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:30.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:31.099+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:31.098+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:54:31.101+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:54:31.126+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:31.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:54:31.142+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:54:31.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:54:31.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T18:55:01.308+0000] {processor.py:186} INFO - Started process (PID=769) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:01.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:55:01.311+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:01.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:01.482+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:01.481+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:55:01.484+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:01.509+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:01.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:55:01.526+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:01.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:55:01.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.242 seconds
[2024-12-28T18:55:31.703+0000] {processor.py:186} INFO - Started process (PID=778) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:31.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:55:31.706+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:31.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:31.932+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:31.930+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:55:31.934+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:55:31.956+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:31.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:55:31.968+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:55:31.967+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:55:31.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.285 seconds
[2024-12-28T18:56:02.129+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:02.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:56:02.134+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:02.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:02.360+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:02.359+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:56:02.362+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:02.389+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:02.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:56:02.409+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:02.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:56:02.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.305 seconds
[2024-12-28T18:56:32.585+0000] {processor.py:186} INFO - Started process (PID=796) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:32.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:56:32.587+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:32.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:32.752+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:32.751+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:56:32.754+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:56:32.774+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:32.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:56:32.785+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:56:32.785+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:56:32.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:57:02.956+0000] {processor.py:186} INFO - Started process (PID=805) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:02.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:57:02.959+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:02.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:03.187+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:03.186+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:57:03.189+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:03.210+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:03.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:57:03.225+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:03.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:57:03.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.290 seconds
[2024-12-28T18:57:33.386+0000] {processor.py:186} INFO - Started process (PID=814) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:33.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:57:33.391+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:33.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:33.543+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:33.542+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:57:33.545+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:57:33.569+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:33.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:57:33.585+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:57:33.585+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:57:33.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T18:58:03.750+0000] {processor.py:186} INFO - Started process (PID=823) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:03.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:58:03.754+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:03.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:03.903+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:03.903+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:58:03.905+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:03.926+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:03.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:58:03.938+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:03.937+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:58:03.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T18:58:34.104+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:34.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:58:34.107+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:34.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:34.281+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:34.280+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:58:34.283+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:58:34.305+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:34.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:58:34.318+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:58:34.318+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:58:34.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T18:59:04.477+0000] {processor.py:186} INFO - Started process (PID=841) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:04.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:59:04.481+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:04.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:04.634+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:04.633+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:59:04.636+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:04.656+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:04.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:59:04.667+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:04.667+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:59:04.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T18:59:34.838+0000] {processor.py:186} INFO - Started process (PID=850) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:34.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T18:59:34.841+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:34.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:35.014+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:35.013+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T18:59:35.016+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T18:59:35.036+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:35.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T18:59:35.047+0000] {logging_mixin.py:190} INFO - [2024-12-28T18:59:35.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T18:59:35.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T19:00:05.209+0000] {processor.py:186} INFO - Started process (PID=859) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:05.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:00:05.212+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:05.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:05.364+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:05.364+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:00:05.366+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:05.390+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:05.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:00:05.407+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:05.407+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:00:05.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T19:00:35.576+0000] {processor.py:186} INFO - Started process (PID=868) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:35.577+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:00:35.579+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:35.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:35.745+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:35.743+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:00:35.747+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:00:35.776+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:35.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:00:35.792+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:00:35.791+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:00:35.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2024-12-28T19:01:05.974+0000] {processor.py:186} INFO - Started process (PID=877) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:05.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:01:05.977+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:05.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:06.152+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:06.151+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:01:06.153+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:06.174+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:06.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:01:06.186+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:06.186+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:01:06.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T19:01:36.349+0000] {processor.py:186} INFO - Started process (PID=886) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:36.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:01:36.352+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:36.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:36.502+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:36.501+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:01:36.504+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:01:36.523+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:36.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:01:36.535+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:01:36.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:01:36.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.204 seconds
[2024-12-28T19:02:06.701+0000] {processor.py:186} INFO - Started process (PID=894) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:06.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:02:06.704+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:06.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:06.856+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:06.855+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:02:06.857+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:06.877+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:06.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:02:06.888+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:06.888+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:02:06.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T19:02:37.057+0000] {processor.py:186} INFO - Started process (PID=903) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:37.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:02:37.060+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:37.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:37.234+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:37.233+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:02:37.236+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:02:37.260+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:37.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:02:37.276+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:02:37.276+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:02:37.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2024-12-28T19:03:07.449+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:07.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:03:07.452+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:07.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:07.680+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:07.679+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:03:07.683+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:07.708+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:07.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:03:07.725+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:07.725+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:03:07.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.306 seconds
[2024-12-28T19:03:37.898+0000] {processor.py:186} INFO - Started process (PID=922) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:37.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:03:37.901+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:37.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:38.051+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:38.050+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:03:38.053+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:03:38.074+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:38.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:03:38.086+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:03:38.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:03:38.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T19:04:08.251+0000] {processor.py:186} INFO - Started process (PID=931) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:08.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:04:08.254+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:08.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:08.426+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:08.425+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:04:08.428+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:08.447+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:08.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:04:08.459+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:08.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:04:08.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2024-12-28T19:04:38.620+0000] {processor.py:186} INFO - Started process (PID=941) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:38.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:04:38.623+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:38.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:38.801+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:38.800+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:04:38.803+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:04:38.822+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:38.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:04:38.834+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:04:38.834+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:04:38.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T19:05:08.998+0000] {processor.py:186} INFO - Started process (PID=950) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:08.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:05:09.000+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:09.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:09.174+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:09.173+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:05:09.176+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:09.196+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:09.196+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:05:09.208+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:09.208+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:05:09.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2024-12-28T19:05:39.375+0000] {processor.py:186} INFO - Started process (PID=959) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:39.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:05:39.378+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:39.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:39.563+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:39.562+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:05:39.567+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:05:39.589+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:39.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:05:39.602+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:05:39.602+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:05:39.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.246 seconds
[2024-12-28T19:06:09.763+0000] {processor.py:186} INFO - Started process (PID=968) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:09.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:06:09.766+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:09.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:09.939+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:09.938+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:06:09.941+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:09.962+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:09.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:06:09.974+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:09.973+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:06:09.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T19:06:40.131+0000] {processor.py:186} INFO - Started process (PID=977) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:40.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:06:40.136+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:40.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:40.288+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:40.288+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:06:40.290+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:06:40.316+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:40.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:06:40.331+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:06:40.331+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:06:40.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T19:07:10.498+0000] {processor.py:186} INFO - Started process (PID=986) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:10.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:07:10.500+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:10.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:10.650+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:10.649+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:07:10.651+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:10.675+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:10.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:07:10.691+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:10.690+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:07:10.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T19:07:40.852+0000] {processor.py:186} INFO - Started process (PID=995) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:40.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:07:40.855+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:40.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:41.007+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:41.007+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:07:41.009+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:07:41.030+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:41.029+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:07:41.042+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:07:41.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:07:41.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2024-12-28T19:08:11.200+0000] {processor.py:186} INFO - Started process (PID=1004) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:11.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:08:11.208+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:11.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:11.360+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:11.359+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:08:11.361+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:11.385+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:11.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:08:11.402+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:11.402+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:08:11.416+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T19:08:41.567+0000] {processor.py:186} INFO - Started process (PID=1013) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:41.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:08:41.570+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:41.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:41.773+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:41.772+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:08:41.776+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:08:41.802+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:41.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:08:41.819+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:08:41.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:08:41.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.276 seconds
[2024-12-28T19:09:11.992+0000] {processor.py:186} INFO - Started process (PID=1022) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:11.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:09:11.996+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:11.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:12.185+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:12.184+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:09:12.187+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:12.207+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:12.207+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:09:12.219+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:12.219+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:09:12.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.247 seconds
[2024-12-28T19:09:42.380+0000] {processor.py:186} INFO - Started process (PID=1031) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:42.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:09:42.383+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:42.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:42.537+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:42.536+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:09:42.539+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:09:42.559+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:42.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:09:42.570+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:09:42.570+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:09:42.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T19:10:12.738+0000] {processor.py:186} INFO - Started process (PID=1040) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:12.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:10:12.740+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:12.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:12.976+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:12.975+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:10:12.978+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:13.005+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:13.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:10:13.022+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:13.022+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:10:13.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.308 seconds
[2024-12-28T19:10:43.194+0000] {processor.py:186} INFO - Started process (PID=1055) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:43.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:10:43.197+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:43.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:43.377+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:43.376+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:10:43.380+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:10:43.402+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:43.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:10:43.414+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:10:43.414+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:10:43.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.246 seconds
[2024-12-28T19:11:13.584+0000] {processor.py:186} INFO - Started process (PID=1064) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:13.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:11:13.587+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:13.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:13.738+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:13.737+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:11:13.740+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:13.764+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:13.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:11:13.781+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:13.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:11:13.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T19:11:43.970+0000] {processor.py:186} INFO - Started process (PID=1072) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:43.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:11:43.978+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:43.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:44.220+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:44.219+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:11:44.223+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:11:44.261+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:44.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:11:44.279+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:11:44.279+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:11:44.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.343 seconds
[2024-12-28T19:12:14.467+0000] {processor.py:186} INFO - Started process (PID=1081) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:14.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:12:14.469+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:14.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:14.620+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:14.619+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:12:14.622+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:14.642+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:14.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:12:14.654+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:14.654+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:12:14.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T19:12:44.814+0000] {processor.py:186} INFO - Started process (PID=1090) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:44.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:12:44.817+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:44.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:44.989+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:44.988+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:12:44.991+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:12:45.015+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:45.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:12:45.030+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:12:45.030+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:12:45.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T19:13:15.190+0000] {processor.py:186} INFO - Started process (PID=1099) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:15.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:13:15.193+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:15.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:15.360+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:15.359+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:13:15.362+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:15.381+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:15.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:13:15.393+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:15.393+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:13:15.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T19:13:45.556+0000] {processor.py:186} INFO - Started process (PID=1108) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:45.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:13:45.559+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:45.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:45.730+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:45.729+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:13:45.732+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:13:45.755+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:45.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:13:45.773+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:13:45.772+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:13:45.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2024-12-28T19:14:15.947+0000] {processor.py:186} INFO - Started process (PID=1117) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:15.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:14:15.950+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:15.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:16.103+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:16.102+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:14:16.105+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:16.129+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:16.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:14:16.146+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:16.146+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:14:16.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T19:14:46.312+0000] {processor.py:186} INFO - Started process (PID=1126) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:46.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:14:46.315+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:46.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:46.474+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:46.473+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: test.sql
[2024-12-28T19:14:46.476+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:14:46.496+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:46.496+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:14:46.508+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:14:46.507+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:14:46.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.215 seconds
[2024-12-28T19:15:10.656+0000] {processor.py:186} INFO - Started process (PID=1129) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:10.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:15:10.667+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:10.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:10.831+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:10.830+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: /test.sql
[2024-12-28T19:15:10.833+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:10.989+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:10.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:15:11.000+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:10.999+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:15:11.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.366 seconds
[2024-12-28T19:15:15.054+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:15.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:15:15.056+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:15.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:15.206+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:15.205+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags//test.sql
[2024-12-28T19:15:15.208+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:15.217+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:15.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:15:15.229+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:15.229+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:15:15.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.197 seconds
[2024-12-28T19:15:45.277+0000] {processor.py:186} INFO - Started process (PID=1145) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:45.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:15:45.281+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:45.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:45.429+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:45.428+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags//test.sql
[2024-12-28T19:15:45.431+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:15:45.526+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:45.525+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:15:45.535+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:15:45.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:15:45.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.278 seconds
[2024-12-28T19:16:15.610+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:15.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:16:15.612+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:15.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:15.767+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:15.766+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags//test.sql
[2024-12-28T19:16:15.769+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:15.793+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:15.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:16:15.809+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:15.809+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:16:15.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T19:16:24.864+0000] {processor.py:186} INFO - Started process (PID=1157) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:24.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:16:24.873+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:24.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:25.021+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:25.021+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:16:25.023+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:25.115+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:25.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:16:25.126+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:25.125+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:16:25.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.283 seconds
[2024-12-28T19:16:55.224+0000] {processor.py:186} INFO - Started process (PID=1166) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:55.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:16:55.226+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:55.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:55.373+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:55.372+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:16:55.375+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:16:55.395+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:55.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:16:55.408+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:16:55.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:16:55.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:17:25.604+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:25.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:17:25.608+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:25.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:25.756+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:25.755+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:17:25.758+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:25.778+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:25.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:17:25.790+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:25.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:17:25.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:17:55.952+0000] {processor.py:186} INFO - Started process (PID=1184) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:55.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:17:55.954+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:55.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:56.102+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:56.102+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:17:56.104+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:17:56.124+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:56.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:17:56.136+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:17:56.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:17:56.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.204 seconds
[2024-12-28T19:18:26.361+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:26.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:18:26.364+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:26.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:26.511+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:26.510+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:18:26.513+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:26.533+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:26.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:18:26.545+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:26.544+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:18:26.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:18:56.715+0000] {processor.py:186} INFO - Started process (PID=1202) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:56.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:18:56.718+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:56.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:56.867+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:56.866+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:18:56.869+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:18:56.893+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:56.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:18:56.909+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:18:56.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:18:56.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T19:19:27.058+0000] {processor.py:186} INFO - Started process (PID=1211) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:27.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:19:27.061+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:27.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:27.210+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:27.209+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:19:27.212+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:27.236+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:27.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:19:27.249+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:27.249+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:19:27.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T19:19:57.413+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:57.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:19:57.416+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:57.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:57.564+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:57.563+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:19:57.567+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:19:57.591+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:57.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:19:57.604+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:19:57.603+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:19:57.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T19:20:27.784+0000] {processor.py:186} INFO - Started process (PID=1229) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:27.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:20:27.788+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:27.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:27.935+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:27.934+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:20:27.937+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:27.957+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:27.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:20:27.968+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:27.968+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:20:27.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:20:54.319+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:54.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:20:54.322+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:54.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:54.469+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:20:54.562+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:54.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:20:54.572+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:20:54.572+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:20:54.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.272 seconds
[2024-12-28T19:21:24.676+0000] {processor.py:186} INFO - Started process (PID=1247) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:24.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:21:24.679+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:24.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:24.826+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:24.846+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:24.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:21:24.858+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:24.858+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:21:24.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.200 seconds
[2024-12-28T19:21:35.932+0000] {processor.py:186} INFO - Started process (PID=1248) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:35.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:21:35.934+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:35.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:36.083+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:36.194+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:36.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:21:36.204+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:36.204+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:21:36.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.294 seconds
[2024-12-28T19:21:37.946+0000] {processor.py:186} INFO - Started process (PID=1249) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:37.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:21:37.949+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:37.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:38.100+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:38.099+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:21:38.102+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:21:38.114+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:38.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:21:38.128+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:21:38.128+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:21:38.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T19:22:08.307+0000] {processor.py:186} INFO - Started process (PID=1258) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:08.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:22:08.310+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:08.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:08.457+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:08.456+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:22:08.459+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:08.576+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:08.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:22:08.587+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:08.587+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:22:08.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.300 seconds
[2024-12-28T19:22:38.662+0000] {processor.py:186} INFO - Started process (PID=1267) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:38.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:22:38.665+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:38.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:38.813+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:38.812+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:22:38.815+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:22:38.835+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:38.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:22:38.849+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:22:38.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:22:38.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T19:23:09.007+0000] {processor.py:186} INFO - Started process (PID=1276) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:09.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:23:09.011+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:09.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:09.166+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:09.165+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:23:09.168+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:09.188+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:09.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:23:09.200+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:09.199+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:23:09.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T19:23:37.364+0000] {processor.py:186} INFO - Started process (PID=1285) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:37.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:23:37.366+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:37.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:37.520+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:37.519+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:23:37.522+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:37.542+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:37.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:23:37.554+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:37.554+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:23:37.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T19:23:39.377+0000] {processor.py:186} INFO - Started process (PID=1286) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:39.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:23:39.379+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:39.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:39.528+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:39.527+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:23:39.530+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:39.550+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:39.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:23:39.562+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:39.562+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:23:39.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T19:23:44.405+0000] {processor.py:186} INFO - Started process (PID=1293) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:44.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:23:44.407+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:44.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:44.565+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:44.564+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:23:44.567+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:23:44.587+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:44.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:23:44.599+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:23:44.599+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:23:44.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T19:24:03.793+0000] {processor.py:186} INFO - Started process (PID=1296) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:03.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:24:03.795+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:03.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:03.945+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:03.944+0000] {templater.py:94} ERROR - Failed to resolve template field '_sql'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 92, in resolve_template_files
    setattr(self, field, env.loader.get_source(env, content)[0])  # type: ignore
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/loaders.py", line 207, in get_source
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: dags/include/test.sql
[2024-12-28T19:24:03.947+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:04.036+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:04.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:24:04.046+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:04.046+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:24:04.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.274 seconds
[2024-12-28T19:24:08.961+0000] {processor.py:186} INFO - Started process (PID=1297) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:08.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:24:08.963+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:08.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:09.115+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:09.123+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:09.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:24:09.136+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:09.135+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:24:09.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.196 seconds
[2024-12-28T19:24:39.324+0000] {processor.py:186} INFO - Started process (PID=1306) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:39.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:24:39.328+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:39.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:39.476+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:24:39.566+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:39.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:24:39.577+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:24:39.577+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:24:39.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.273 seconds
[2024-12-28T19:25:09.698+0000] {processor.py:186} INFO - Started process (PID=1315) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:09.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:25:09.701+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:09.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:09.854+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:09.873+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:09.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:25:09.885+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:09.885+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:25:09.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T19:25:35.029+0000] {processor.py:186} INFO - Started process (PID=1324) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:35.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:25:35.032+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:35.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:35.181+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:35.283+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:35.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:25:35.294+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:35.294+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:25:35.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.286 seconds
[2024-12-28T19:25:38.304+0000] {processor.py:186} INFO - Started process (PID=1325) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:38.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:25:38.307+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:38.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:38.456+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:38.465+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:38.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:25:38.478+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:38.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:25:38.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.194 seconds
[2024-12-28T19:25:41.355+0000] {processor.py:186} INFO - Started process (PID=1326) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:41.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:25:41.358+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:41.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:41.507+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:25:41.516+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:41.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:25:41.529+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:25:41.528+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:25:41.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.194 seconds
[2024-12-28T19:26:11.791+0000] {processor.py:186} INFO - Started process (PID=1335) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:11.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:26:11.793+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:11.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:11.943+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:12.031+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:12.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:26:12.041+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:12.041+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:26:12.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.269 seconds
[2024-12-28T19:26:42.264+0000] {processor.py:186} INFO - Started process (PID=1344) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:42.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:26:42.267+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:42.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:42.420+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:26:42.439+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:42.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:26:42.451+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:26:42.451+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:26:42.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T19:27:12.618+0000] {processor.py:186} INFO - Started process (PID=1353) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:12.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:27:12.621+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:12.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:12.768+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:12.787+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:12.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:27:12.799+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:12.799+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:27:12.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.199 seconds
[2024-12-28T19:27:42.968+0000] {processor.py:186} INFO - Started process (PID=1362) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:42.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:27:42.971+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:42.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:43.119+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:27:43.139+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:43.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:27:43.151+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:27:43.151+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:27:43.166+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:28:13.327+0000] {processor.py:186} INFO - Started process (PID=1371) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:13.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:28:13.330+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:13.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:13.477+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:13.497+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:13.496+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:28:13.509+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:13.509+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:28:13.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:28:43.687+0000] {processor.py:186} INFO - Started process (PID=1380) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:43.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:28:43.689+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:43.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:43.847+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:28:43.868+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:43.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:28:43.879+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:28:43.879+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:28:43.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T19:29:14.055+0000] {processor.py:186} INFO - Started process (PID=1389) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:14.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:29:14.060+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:14.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:14.309+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:14.335+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:14.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:29:14.351+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:14.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:29:14.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.321 seconds
[2024-12-28T19:29:44.416+0000] {processor.py:186} INFO - Started process (PID=1399) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:44.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:29:44.419+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:44.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:44.587+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:29:44.607+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:44.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:29:44.619+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:29:44.618+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:29:44.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T19:30:14.771+0000] {processor.py:186} INFO - Started process (PID=1414) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:14.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:30:14.775+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:14.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:14.924+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:14.944+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:14.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:30:14.955+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:14.955+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:30:14.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T19:30:45.141+0000] {processor.py:186} INFO - Started process (PID=1423) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:45.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:30:45.144+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:45.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:45.302+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:30:45.321+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:45.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:30:45.334+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:30:45.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:30:45.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T19:31:15.497+0000] {processor.py:186} INFO - Started process (PID=1432) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:15.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:31:15.499+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:15.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:15.651+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:15.677+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:15.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:31:15.692+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:15.692+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:31:15.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T19:31:45.855+0000] {processor.py:186} INFO - Started process (PID=1441) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:45.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:31:45.858+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:45.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:46.007+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:31:46.027+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:46.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:31:46.038+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:31:46.038+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:31:46.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.201 seconds
[2024-12-28T19:32:16.215+0000] {processor.py:186} INFO - Started process (PID=1450) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:16.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:32:16.218+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:16.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:16.366+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:16.386+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:16.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:32:16.398+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:16.397+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:32:16.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:32:46.593+0000] {processor.py:186} INFO - Started process (PID=1459) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:46.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:32:46.604+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:46.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:46.868+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:32:46.898+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:46.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:32:46.916+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:32:46.916+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:32:46.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.349 seconds
[2024-12-28T19:33:17.018+0000] {processor.py:186} INFO - Started process (PID=1468) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:17.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:33:17.021+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:17.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:17.171+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:17.191+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:17.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:33:17.203+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:17.203+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:33:17.217+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T19:33:47.437+0000] {processor.py:186} INFO - Started process (PID=1477) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:47.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:33:47.439+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:47.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:47.587+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:33:47.607+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:47.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:33:47.620+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:33:47.620+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:33:47.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.204 seconds
[2024-12-28T19:34:17.811+0000] {processor.py:186} INFO - Started process (PID=1486) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:17.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:34:17.813+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:17.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:17.962+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:17.982+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:17.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:34:17.994+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:17.994+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:34:18.008+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:34:48.170+0000] {processor.py:186} INFO - Started process (PID=1495) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:48.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:34:48.176+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:48.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:48.416+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:34:48.454+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:48.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:34:48.477+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:34:48.477+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:34:48.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.337 seconds
[2024-12-28T19:35:18.544+0000] {processor.py:186} INFO - Started process (PID=1503) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:18.544+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:35:18.546+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:18.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:18.696+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:18.716+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:18.716+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:35:18.727+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:18.727+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:35:18.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:35:48.893+0000] {processor.py:186} INFO - Started process (PID=1512) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:48.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:35:48.896+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:48.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:49.046+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:35:49.066+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:49.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:35:49.078+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:35:49.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:35:49.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T19:36:19.246+0000] {processor.py:186} INFO - Started process (PID=1521) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:19.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:36:19.249+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:19.249+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:19.399+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:19.429+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:19.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:36:19.443+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:19.443+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:36:19.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T19:36:49.599+0000] {processor.py:186} INFO - Started process (PID=1530) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:49.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:36:49.602+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:49.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:49.770+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:36:49.796+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:49.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:36:49.813+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:36:49.812+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:36:49.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2024-12-28T19:37:19.962+0000] {processor.py:186} INFO - Started process (PID=1539) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:19.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:37:19.964+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:19.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:20.118+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:20.143+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:20.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:37:20.159+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:20.158+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:37:20.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T19:37:50.305+0000] {processor.py:186} INFO - Started process (PID=1548) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:50.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:37:50.308+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:50.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:50.456+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:37:50.476+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:50.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:37:50.488+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:37:50.487+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:37:50.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:38:20.652+0000] {processor.py:186} INFO - Started process (PID=1557) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:20.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:38:20.656+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:20.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:20.805+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:20.825+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:20.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:38:20.836+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:20.836+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:38:20.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:38:51.010+0000] {processor.py:186} INFO - Started process (PID=1566) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:51.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:38:51.012+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:51.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:51.160+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:38:51.179+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:51.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:38:51.192+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:38:51.192+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:38:51.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:39:21.372+0000] {processor.py:186} INFO - Started process (PID=1575) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:21.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:39:21.375+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:21.375+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:21.528+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:21.548+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:21.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:39:21.560+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:21.560+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:39:21.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T19:39:51.734+0000] {processor.py:186} INFO - Started process (PID=1584) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:51.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:39:51.737+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:51.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:51.886+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:39:51.906+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:51.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:39:51.918+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:39:51.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:39:51.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2024-12-28T19:40:22.097+0000] {processor.py:186} INFO - Started process (PID=1593) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:22.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:40:22.100+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:22.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:22.249+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:22.269+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:22.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:40:22.280+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:22.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:40:22.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2024-12-28T19:40:52.445+0000] {processor.py:186} INFO - Started process (PID=1602) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:52.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:40:52.448+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:52.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:52.597+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:40:52.619+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:52.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:40:52.631+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:40:52.631+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:40:52.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T19:41:22.836+0000] {processor.py:186} INFO - Started process (PID=1611) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:41:22.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:41:22.838+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:41:22.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:41:22.989+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:41:23.008+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:41:23.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:41:23.020+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:41:23.020+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:41:23.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T19:42:20.832+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:20.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:42:20.840+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:20.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:21.133+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:21.162+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:21.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:42:21.179+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:21.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:42:21.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.403 seconds
[2024-12-28T19:42:48.410+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:48.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:42:48.414+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:48.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:48.647+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:42:48.678+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:48.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:42:48.694+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:42:48.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:42:48.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.308 seconds
[2024-12-28T19:43:18.871+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:18.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:43:18.874+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:18.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:19.045+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:19.065+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:19.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:43:19.076+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:19.076+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:43:19.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T19:43:49.239+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:49.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:43:49.242+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:49.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:49.413+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:43:49.437+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:49.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:43:49.450+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:43:49.450+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:43:49.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T19:44:19.607+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:19.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:44:19.609+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:19.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:19.761+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:19.786+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:19.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:44:19.802+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:19.802+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:44:19.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.345 seconds
[2024-12-28T19:44:50.092+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:50.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:44:50.095+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:50.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:50.259+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:44:50.283+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:50.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:44:50.438+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:44:50.438+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:44:50.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.365 seconds
[2024-12-28T19:45:20.601+0000] {processor.py:186} INFO - Started process (PID=77) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:20.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:45:20.605+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:20.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:20.778+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:20.939+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:20.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:45:20.952+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:20.952+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:45:20.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.372 seconds
[2024-12-28T19:45:51.118+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:51.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:45:51.122+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:51.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:51.375+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:45:51.566+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:51.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:45:51.581+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:45:51.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:45:51.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.487 seconds
[2024-12-28T19:46:21.744+0000] {processor.py:186} INFO - Started process (PID=95) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:21.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:46:21.747+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:21.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:22.045+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:22.062+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:22.062+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:46:22.073+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:22.073+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:46:22.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.346 seconds
[2024-12-28T19:46:52.233+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:52.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:46:52.239+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:52.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:52.537+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:46:52.560+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:52.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:46:52.576+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:46:52.576+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:46:52.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.367 seconds
[2024-12-28T19:47:22.747+0000] {processor.py:186} INFO - Started process (PID=113) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:22.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:47:22.753+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:22.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:22.925+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:22.949+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:22.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:47:22.966+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:22.965+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:47:22.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2024-12-28T19:47:53.136+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:53.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:47:53.138+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:53.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:53.319+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:47:53.345+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:53.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:47:53.360+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:47:53.360+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:47:53.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.247 seconds
[2024-12-28T19:48:23.526+0000] {processor.py:186} INFO - Started process (PID=131) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:23.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:48:23.529+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:23.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:23.701+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:23.724+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:23.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:48:23.736+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:23.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:48:23.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T19:48:53.895+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:53.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:48:53.897+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:53.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:54.052+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:48:54.072+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:54.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:48:54.084+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:48:54.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:48:54.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T19:49:24.246+0000] {processor.py:186} INFO - Started process (PID=149) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:24.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:49:24.252+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:24.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:24.406+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:24.431+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:24.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:49:24.442+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:24.442+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:49:24.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T19:49:54.602+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:54.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:49:54.604+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:54.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:54.753+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:49:54.777+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:54.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:49:54.794+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:49:54.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:49:54.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T19:50:24.962+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:24.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:50:24.964+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:24.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:25.145+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:25.170+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:25.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:50:25.184+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:25.184+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:50:25.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.242 seconds
[2024-12-28T19:50:55.352+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:55.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:50:55.355+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:55.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:55.525+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:50:55.550+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:55.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:50:55.565+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:50:55.565+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:50:55.580+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T19:59:30.259+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:59:30.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T19:59:30.263+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:59:30.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:59:30.449+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T19:59:30.474+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:59:30.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T19:59:30.487+0000] {logging_mixin.py:190} INFO - [2024-12-28T19:59:30.486+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T19:59:30.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.250 seconds
[2024-12-28T20:00:00.655+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:00.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:00:00.657+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:00.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:00.870+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:00.894+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:00.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:00:00.909+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:00.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:00:00.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.275 seconds
[2024-12-28T20:00:31.070+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:31.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:00:31.072+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:31.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:31.227+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:00:31.247+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:31.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:00:31.259+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:00:31.259+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:00:31.273+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T20:01:01.426+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:01.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:01:01.434+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:01.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:01.585+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:01.605+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:01.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:01:01.617+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:01.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:01:01.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.373 seconds
[2024-12-28T20:01:31.940+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:31.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:01:31.943+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:31.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:32.100+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:01:32.125+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:32.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:01:32.270+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:01:32.270+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:01:32.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.350 seconds
[2024-12-28T20:02:02.437+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:02.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:02:02.439+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:02.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:02.675+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:02.860+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:02.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:02:02.876+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:02.876+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:02:02.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.464 seconds
[2024-12-28T20:02:33.049+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:33.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:02:33.052+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:33.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:33.220+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:02:33.369+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:33.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:02:33.379+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:02:33.379+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:02:33.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.349 seconds
[2024-12-28T20:03:03.541+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:03.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:03:03.543+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:03.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:03.815+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:03.833+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:03.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:03:03.843+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:03.843+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:03:03.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.321 seconds
[2024-12-28T20:03:34.006+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:34.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:03:34.009+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:34.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:34.331+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:03:34.353+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:34.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:03:34.363+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:03:34.363+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:03:34.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.377 seconds
[2024-12-28T20:04:04.645+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:04.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:04:04.649+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:04.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:04.833+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:04.856+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:04.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:04:04.869+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:04.869+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:04:04.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.244 seconds
[2024-12-28T20:04:35.030+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:35.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:04:35.033+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:35.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:35.204+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:04:35.224+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:35.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:04:35.236+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:04:35.236+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:04:35.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T20:05:05.403+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:05.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:05:05.407+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:05.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:05.563+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:05.589+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:05.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:05:05.604+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:05.604+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:05:05.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T20:05:35.775+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:35.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:05:35.777+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:35.777+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:35.948+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:05:35.968+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:35.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:05:35.979+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:05:35.979+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:05:35.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T20:06:06.144+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:06.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:06:06.147+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:06.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:06.296+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:06.321+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:06.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:06:06.336+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:06.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:06:06.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T20:06:36.503+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:36.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:06:36.505+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:36.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:36.662+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:06:36.682+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:36.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:06:36.695+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:06:36.695+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:06:36.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T20:07:06.858+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:06.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:07:06.861+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:06.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:07.035+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:07.055+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:07.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:07:07.068+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:07.068+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:07:07.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T20:07:37.227+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:37.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:07:37.230+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:37.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:37.404+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:07:37.425+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:37.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:07:37.437+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:07:37.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:07:37.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:08:07.598+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:07.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:08:07.601+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:07.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:07.763+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:07.783+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:07.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:08:07.795+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:07.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:08:07.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T20:08:37.959+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:37.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:08:37.961+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:37.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:38.135+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:08:38.159+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:38.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:08:38.172+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:08:38.171+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:08:38.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T20:09:08.333+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:08.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:09:08.338+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:08.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:08.513+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:08.537+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:08.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:09:08.552+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:08.551+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:09:08.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2024-12-28T20:09:38.722+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:38.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:09:38.724+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:38.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:38.899+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:09:38.924+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:38.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:09:38.938+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:09:38.938+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:09:38.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T20:10:09.104+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:09.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:10:09.108+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:09.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:09.281+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:09.302+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:09.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:10:09.314+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:09.313+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:10:09.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:10:39.481+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:39.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:10:39.483+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:39.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:39.649+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:10:39.675+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:39.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:10:39.688+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:10:39.688+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:10:39.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:11:09.859+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:09.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:11:09.862+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:09.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:10.051+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:10.070+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:10.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:11:10.082+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:10.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:11:10.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.245 seconds
[2024-12-28T20:11:40.243+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:40.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:11:40.246+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:40.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:40.422+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:11:40.447+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:40.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:11:40.463+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:11:40.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:11:40.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.242 seconds
[2024-12-28T20:12:10.630+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:10.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:12:10.633+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:10.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:10.793+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:10.813+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:10.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:12:10.826+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:10.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:12:10.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T20:12:40.990+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:40.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:12:40.993+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:40.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:41.155+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:12:41.176+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:41.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:12:41.188+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:12:41.188+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:12:41.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T20:13:11.355+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:11.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:13:11.359+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:11.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:11.508+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:11.533+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:11.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:13:11.549+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:11.548+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:13:11.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.215 seconds
[2024-12-28T20:13:41.712+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:41.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:13:41.714+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:41.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:41.868+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:13:41.892+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:41.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:13:41.908+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:13:41.908+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:13:41.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T20:14:12.072+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:12.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:14:12.076+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:12.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:12.230+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:12.250+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:12.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:14:12.263+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:12.263+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:14:12.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T20:14:42.432+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:42.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:14:42.434+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:42.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:42.609+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:14:42.629+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:42.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:14:42.641+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:14:42.640+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:14:42.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:15:12.803+0000] {processor.py:186} INFO - Started process (PID=309) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:12.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:15:12.806+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:12.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:12.960+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:12.980+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:12.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:15:12.992+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:12.992+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:15:13.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2024-12-28T20:15:43.158+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:43.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:15:43.161+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:43.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:43.324+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:15:43.349+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:43.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:15:43.365+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:15:43.364+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:15:43.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:16:13.539+0000] {processor.py:186} INFO - Started process (PID=327) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:13.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:16:13.548+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:13.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:13.722+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:13.746+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:13.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:16:13.759+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:13.759+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:16:13.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2024-12-28T20:16:43.923+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:43.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:16:43.926+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:43.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:44.110+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:16:44.130+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:44.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:16:44.141+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:16:44.141+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:16:44.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2024-12-28T20:17:14.303+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:14.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:17:14.311+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:14.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:14.464+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:14.485+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:14.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:17:14.496+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:14.496+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:17:14.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T20:17:44.657+0000] {processor.py:186} INFO - Started process (PID=354) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:44.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:17:44.659+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:44.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:44.816+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:17:44.836+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:44.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:17:44.849+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:17:44.849+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:17:44.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T20:18:15.009+0000] {processor.py:186} INFO - Started process (PID=363) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:15.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:18:15.013+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:15.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:15.177+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:15.200+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:15.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:18:15.215+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:15.215+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:18:15.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2024-12-28T20:18:45.381+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:45.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:18:45.384+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:45.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:45.533+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:18:45.559+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:45.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:18:45.574+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:18:45.574+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:18:45.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T20:19:15.744+0000] {processor.py:186} INFO - Started process (PID=381) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:15.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:19:15.755+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:15.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:15.918+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:15.943+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:15.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:19:15.956+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:15.955+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:19:15.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T20:19:46.132+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:46.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:19:46.135+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:46.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:46.326+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:19:46.346+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:46.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:19:46.359+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:19:46.358+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:19:46.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.246 seconds
[2024-12-28T20:20:16.518+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:16.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:20:16.527+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:16.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:16.703+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:16.723+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:16.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:20:16.735+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:16.734+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:20:16.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2024-12-28T20:20:46.901+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:46.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:20:46.904+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:46.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:47.061+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:20:47.086+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:47.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:20:47.103+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:20:47.103+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:20:47.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T20:21:17.271+0000] {processor.py:186} INFO - Started process (PID=423) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:17.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:21:17.274+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:17.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:17.466+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:17.486+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:17.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:21:17.498+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:17.498+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:21:17.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.248 seconds
[2024-12-28T20:21:47.656+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:47.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:21:47.659+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:47.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:47.815+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:21:47.836+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:47.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:21:47.847+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:21:47.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:21:47.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T20:22:18.007+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:18.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:22:18.010+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:18.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:18.187+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:18.211+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:18.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:22:18.226+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:18.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:22:18.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.241 seconds
[2024-12-28T20:22:48.395+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:48.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:22:48.399+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:48.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:48.550+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:22:48.570+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:48.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:22:48.582+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:22:48.581+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:22:48.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T20:23:18.746+0000] {processor.py:186} INFO - Started process (PID=459) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:18.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:23:18.749+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:18.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:18.913+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:18.934+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:18.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:23:18.946+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:18.946+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:23:18.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T20:23:49.104+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:49.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:23:49.106+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:49.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:49.278+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:23:49.299+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:49.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:23:49.311+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:23:49.311+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:23:49.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2024-12-28T20:24:19.474+0000] {processor.py:186} INFO - Started process (PID=477) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:19.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:24:19.476+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:19.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:19.643+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:19.668+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:19.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:24:19.683+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:19.683+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:24:19.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T20:24:49.857+0000] {processor.py:186} INFO - Started process (PID=486) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:49.858+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:24:49.860+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:49.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:50.043+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:24:50.070+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:50.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:24:50.086+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:24:50.086+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:24:50.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.250 seconds
[2024-12-28T20:25:20.245+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:20.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:25:20.249+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:20.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:20.405+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:20.425+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:20.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:25:20.437+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:20.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:25:20.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T20:25:50.604+0000] {processor.py:186} INFO - Started process (PID=504) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:50.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:25:50.609+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:50.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:50.787+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:25:50.807+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:50.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:25:50.819+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:25:50.819+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:25:50.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2024-12-28T20:26:20.985+0000] {processor.py:186} INFO - Started process (PID=513) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:20.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:26:20.988+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:20.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:21.163+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:21.183+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:21.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:26:21.196+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:21.196+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:26:21.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T20:26:51.361+0000] {processor.py:186} INFO - Started process (PID=522) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:51.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:26:51.364+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:51.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:51.515+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:26:51.536+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:51.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:26:51.548+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:26:51.547+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:26:51.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T20:27:21.708+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:21.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:27:21.711+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:21.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:21.885+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:21.905+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:21.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:27:21.918+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:21.918+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:27:21.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2024-12-28T20:27:52.080+0000] {processor.py:186} INFO - Started process (PID=540) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:52.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:27:52.083+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:52.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:52.245+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:27:52.269+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:52.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:27:52.285+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:27:52.285+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:27:52.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2024-12-28T20:28:22.454+0000] {processor.py:186} INFO - Started process (PID=549) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:22.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:28:22.458+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:22.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:22.699+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:22.728+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:22.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:28:22.744+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:22.744+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:28:22.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.314 seconds
[2024-12-28T20:28:52.912+0000] {processor.py:186} INFO - Started process (PID=558) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:52.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:28:52.915+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:52.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:53.065+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:28:53.085+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:53.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:28:53.098+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:28:53.098+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:28:53.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T20:29:23.259+0000] {processor.py:186} INFO - Started process (PID=567) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:23.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:29:23.262+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:23.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:23.415+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:23.435+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:23.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:29:23.447+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:23.447+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:29:23.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T20:29:53.626+0000] {processor.py:186} INFO - Started process (PID=576) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:53.626+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:29:53.628+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:53.628+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:53.785+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:29:53.811+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:53.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:29:53.826+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:29:53.826+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:29:53.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T20:30:23.989+0000] {processor.py:186} INFO - Started process (PID=585) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:23.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:30:23.992+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:23.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:24.165+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:24.185+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:24.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:30:24.197+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:24.197+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:30:24.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:30:54.361+0000] {processor.py:186} INFO - Started process (PID=594) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:54.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:30:54.364+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:54.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:54.517+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:30:54.542+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:54.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:30:54.556+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:30:54.556+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:30:54.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T20:31:24.720+0000] {processor.py:186} INFO - Started process (PID=603) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:24.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:31:24.723+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:24.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:24.877+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:24.902+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:24.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:31:24.917+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:24.917+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:31:24.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2024-12-28T20:31:55.087+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:55.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:31:55.090+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:55.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:55.248+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:31:55.267+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:55.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:31:55.280+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:31:55.280+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:31:55.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T20:32:25.440+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:25.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:32:25.443+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:25.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:25.611+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:25.637+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:25.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:32:25.650+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:25.649+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:32:25.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:32:55.808+0000] {processor.py:186} INFO - Started process (PID=630) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:55.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:32:55.811+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:55.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:56.040+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:32:56.067+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:56.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:32:56.083+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:32:56.083+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:32:56.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.300 seconds
[2024-12-28T20:33:26.255+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:26.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:33:26.258+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:26.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:26.408+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:26.433+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:26.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:33:26.446+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:26.445+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:33:26.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2024-12-28T20:33:56.612+0000] {processor.py:186} INFO - Started process (PID=648) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:56.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:33:56.615+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:56.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:56.783+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:33:56.803+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:56.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:33:56.815+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:33:56.815+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:33:56.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T20:34:26.976+0000] {processor.py:186} INFO - Started process (PID=657) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:26.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:34:26.978+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:26.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:27.154+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:27.178+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:27.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:34:27.194+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:27.193+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:34:27.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.241 seconds
[2024-12-28T20:34:57.372+0000] {processor.py:186} INFO - Started process (PID=666) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:57.373+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:34:57.375+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:57.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:57.556+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:34:57.578+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:57.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:34:57.591+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:34:57.591+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:34:57.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2024-12-28T20:35:27.744+0000] {processor.py:186} INFO - Started process (PID=675) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:27.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:35:27.747+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:27.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:27.903+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:27.928+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:27.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:35:27.943+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:27.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:35:27.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T20:35:58.106+0000] {processor.py:186} INFO - Started process (PID=684) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:58.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:35:58.109+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:58.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:58.259+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:35:58.283+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:58.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:35:58.299+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:35:58.299+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:35:58.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T20:36:28.467+0000] {processor.py:186} INFO - Started process (PID=693) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:28.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:36:28.470+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:28.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:28.668+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:28.694+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:28.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:36:28.710+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:28.710+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:36:28.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.268 seconds
[2024-12-28T20:36:58.880+0000] {processor.py:186} INFO - Started process (PID=702) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:58.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:36:58.883+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:58.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:59.038+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:36:59.058+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:59.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:36:59.071+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:36:59.071+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:36:59.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T20:37:29.235+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:29.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:37:29.237+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:29.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:29.391+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:29.416+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:29.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:37:29.433+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:29.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:37:29.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T20:37:59.599+0000] {processor.py:186} INFO - Started process (PID=720) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:59.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:37:59.602+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:59.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:59.756+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:37:59.778+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:59.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:37:59.790+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:37:59.790+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:37:59.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T20:38:29.952+0000] {processor.py:186} INFO - Started process (PID=729) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:38:29.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:38:29.955+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:38:29.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:38:30.124+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:38:30.151+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:38:30.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:38:30.165+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:38:30.164+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:38:30.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T20:39:00.330+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:00.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:39:00.336+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:00.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:00.492+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:00.512+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:00.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:39:00.525+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:00.525+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:39:00.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T20:39:30.683+0000] {processor.py:186} INFO - Started process (PID=747) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:30.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:39:30.685+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:30.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:30.853+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:39:30.877+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:30.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:39:30.893+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:39:30.892+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:39:30.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T20:40:01.067+0000] {processor.py:186} INFO - Started process (PID=756) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:01.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:40:01.070+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:01.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:01.220+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:01.245+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:01.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:40:01.262+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:01.262+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:40:01.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T20:40:31.429+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:31.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:40:31.433+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:31.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:31.654+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:40:31.682+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:31.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:40:31.698+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:40:31.697+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:40:31.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.292 seconds
[2024-12-28T20:41:01.863+0000] {processor.py:186} INFO - Started process (PID=774) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:01.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:41:01.866+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:01.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:02.024+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:02.045+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:02.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:41:02.057+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:02.056+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:41:02.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T20:41:32.225+0000] {processor.py:186} INFO - Started process (PID=783) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:32.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:41:32.227+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:32.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:32.392+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:41:32.416+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:32.416+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:41:32.432+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:41:32.432+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:41:32.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:42:02.599+0000] {processor.py:186} INFO - Started process (PID=792) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:02.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:42:02.602+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:02.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:02.804+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:02.830+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:02.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:42:02.848+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:02.847+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:42:02.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.274 seconds
[2024-12-28T20:42:33.016+0000] {processor.py:186} INFO - Started process (PID=801) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:33.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:42:33.018+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:33.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:33.193+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:42:33.213+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:33.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:42:33.226+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:42:33.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:42:33.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T20:43:03.390+0000] {processor.py:186} INFO - Started process (PID=810) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:03.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:43:03.394+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:03.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:03.580+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:03.601+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:03.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:43:03.616+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:03.616+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:43:03.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.250 seconds
[2024-12-28T20:43:33.780+0000] {processor.py:186} INFO - Started process (PID=819) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:33.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:43:33.783+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:33.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:33.938+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:43:33.960+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:33.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:43:33.972+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:43:33.972+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:43:33.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2024-12-28T20:44:04.140+0000] {processor.py:186} INFO - Started process (PID=829) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:04.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:44:04.144+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:04.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:04.317+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:04.337+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:04.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:44:04.348+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:04.348+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:44:04.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T20:44:34.520+0000] {processor.py:186} INFO - Started process (PID=838) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:34.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:44:34.522+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:34.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:34.699+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:44:34.719+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:34.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:44:34.731+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:44:34.731+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:44:34.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T20:45:04.904+0000] {processor.py:186} INFO - Started process (PID=847) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:04.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:45:04.907+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:04.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:05.057+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:05.081+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:05.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:45:05.097+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:05.097+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:45:05.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T20:45:35.263+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:35.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:45:35.266+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:35.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:35.429+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:45:35.449+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:35.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:45:35.462+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:45:35.462+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:45:35.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T20:46:05.620+0000] {processor.py:186} INFO - Started process (PID=865) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:05.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:46:05.623+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:05.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:05.781+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:05.807+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:05.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:46:05.822+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:05.822+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:46:05.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T20:46:35.984+0000] {processor.py:186} INFO - Started process (PID=874) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:35.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:46:35.987+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:35.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:36.163+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:46:36.189+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:36.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:46:36.204+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:46:36.204+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:46:36.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.242 seconds
[2024-12-28T20:47:06.373+0000] {processor.py:186} INFO - Started process (PID=883) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:06.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:47:06.377+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:06.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:06.534+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:06.558+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:06.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:47:06.573+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:06.573+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:47:06.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T20:47:36.740+0000] {processor.py:186} INFO - Started process (PID=892) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:36.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:47:36.742+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:36.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:36.916+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:47:36.940+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:36.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:47:36.953+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:47:36.953+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:47:36.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T20:48:07.123+0000] {processor.py:186} INFO - Started process (PID=901) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:07.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:48:07.127+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:07.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:07.286+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:07.306+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:07.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:48:07.320+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:07.320+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:48:07.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.217 seconds
[2024-12-28T20:48:37.479+0000] {processor.py:186} INFO - Started process (PID=911) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:37.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:48:37.482+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:37.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:37.651+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:48:37.671+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:37.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:48:37.685+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:48:37.684+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:48:37.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T20:49:07.851+0000] {processor.py:186} INFO - Started process (PID=920) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:07.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:49:07.855+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:07.855+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:08.064+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:08.088+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:08.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:49:08.101+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:08.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:49:08.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.268 seconds
[2024-12-28T20:49:38.266+0000] {processor.py:186} INFO - Started process (PID=929) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:38.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:49:38.269+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:38.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:38.442+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:49:38.462+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:38.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:49:38.474+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:49:38.474+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:49:38.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2024-12-28T20:50:08.643+0000] {processor.py:186} INFO - Started process (PID=938) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:08.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:50:08.646+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:08.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:08.800+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:08.825+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:08.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:50:08.837+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:08.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:50:08.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T20:50:38.996+0000] {processor.py:186} INFO - Started process (PID=948) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:38.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:50:38.999+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:38.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:39.168+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:50:39.188+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:39.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:50:39.200+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:50:39.200+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:50:39.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2024-12-28T20:51:09.362+0000] {processor.py:186} INFO - Started process (PID=957) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:09.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:51:09.366+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:09.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:09.522+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:09.543+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:09.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:51:09.555+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:09.555+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:51:09.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T20:51:39.715+0000] {processor.py:186} INFO - Started process (PID=966) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:39.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:51:39.718+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:39.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:39.868+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:51:39.894+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:39.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:51:39.909+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:51:39.909+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:51:39.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T20:52:10.079+0000] {processor.py:186} INFO - Started process (PID=975) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:10.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:52:10.082+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:10.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:10.238+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:10.259+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:10.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:52:10.270+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:10.270+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:52:10.287+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.214 seconds
[2024-12-28T20:52:40.439+0000] {processor.py:186} INFO - Started process (PID=984) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:40.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:52:40.442+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:40.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:40.668+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:52:40.694+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:40.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:52:40.710+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:52:40.710+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:52:40.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.297 seconds
[2024-12-28T20:53:10.875+0000] {processor.py:186} INFO - Started process (PID=993) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:10.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:53:10.878+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:10.878+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:11.037+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:11.061+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:11.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:53:11.077+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:11.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:53:11.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T20:53:41.242+0000] {processor.py:186} INFO - Started process (PID=1002) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:41.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:53:41.244+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:41.244+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:41.408+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:53:41.428+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:41.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:53:41.441+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:53:41.441+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:53:41.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T20:54:11.601+0000] {processor.py:186} INFO - Started process (PID=1011) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:11.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:54:11.605+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:11.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:11.761+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:11.781+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:11.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:54:11.794+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:11.793+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:54:11.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2024-12-28T20:54:41.960+0000] {processor.py:186} INFO - Started process (PID=1020) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:41.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:54:41.963+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:41.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:42.121+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:54:42.142+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:42.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:54:42.154+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:54:42.154+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:54:42.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T20:55:12.323+0000] {processor.py:186} INFO - Started process (PID=1029) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:12.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:55:12.326+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:12.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:12.485+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:12.505+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:12.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:55:12.517+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:12.517+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:55:12.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.215 seconds
[2024-12-28T20:55:42.680+0000] {processor.py:186} INFO - Started process (PID=1038) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:42.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:55:42.683+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:42.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:42.836+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:55:42.856+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:42.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:55:42.868+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:55:42.868+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:55:42.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2024-12-28T20:56:13.031+0000] {processor.py:186} INFO - Started process (PID=1047) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:13.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:56:13.034+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:13.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:13.190+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:13.215+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:13.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:56:13.231+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:13.231+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:56:13.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.224 seconds
[2024-12-28T20:56:43.395+0000] {processor.py:186} INFO - Started process (PID=1055) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:43.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:56:43.398+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:43.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:43.560+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:56:43.580+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:43.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:56:43.594+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:56:43.593+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:56:43.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T20:57:13.761+0000] {processor.py:186} INFO - Started process (PID=1064) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:13.762+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:57:13.764+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:13.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:13.919+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:13.945+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:13.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:57:13.960+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:13.960+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:57:13.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2024-12-28T20:57:44.125+0000] {processor.py:186} INFO - Started process (PID=1073) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:44.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:57:44.128+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:44.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:44.296+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:57:44.321+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:44.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:57:44.336+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:57:44.336+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:57:44.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T20:58:14.504+0000] {processor.py:186} INFO - Started process (PID=1082) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:14.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:58:14.507+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:14.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:14.683+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:14.703+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:14.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:58:14.715+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:14.715+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:58:14.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2024-12-28T20:58:44.877+0000] {processor.py:186} INFO - Started process (PID=1091) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:44.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:58:44.879+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:44.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:45.042+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:58:45.065+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:45.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:58:45.077+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:58:45.077+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:58:45.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T20:59:15.243+0000] {processor.py:186} INFO - Started process (PID=1100) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:15.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:59:15.247+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:15.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:15.398+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:15.423+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:15.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:59:15.439+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:15.439+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:59:15.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T20:59:45.614+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:45.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T20:59:45.617+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:45.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:45.768+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T20:59:45.790+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:45.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T20:59:45.804+0000] {logging_mixin.py:190} INFO - [2024-12-28T20:59:45.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T20:59:45.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2024-12-28T21:00:15.966+0000] {processor.py:186} INFO - Started process (PID=1118) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:15.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:00:15.973+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:15.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:16.139+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:16.164+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:16.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:00:16.180+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:16.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:00:16.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T21:00:46.346+0000] {processor.py:186} INFO - Started process (PID=1127) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:46.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:00:46.349+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:46.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:46.549+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:00:46.575+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:46.575+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:00:46.593+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:00:46.592+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:00:46.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.271 seconds
[2024-12-28T21:01:16.762+0000] {processor.py:186} INFO - Started process (PID=1136) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:16.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:01:16.768+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:16.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:16.926+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:16.951+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:16.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:01:16.966+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:16.966+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:01:16.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2024-12-28T21:01:47.128+0000] {processor.py:186} INFO - Started process (PID=1145) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:47.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:01:47.134+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:47.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:47.307+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:01:47.328+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:47.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:01:47.340+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:01:47.340+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:01:47.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T21:02:17.506+0000] {processor.py:186} INFO - Started process (PID=1154) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:17.506+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:02:17.509+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:17.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:17.760+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:17.787+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:17.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:02:17.804+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:17.803+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:02:17.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.322 seconds
[2024-12-28T21:02:47.946+0000] {processor.py:186} INFO - Started process (PID=1163) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:47.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:02:47.949+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:47.949+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:48.101+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:02:48.127+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:48.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:02:48.142+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:02:48.142+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:02:48.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T21:03:18.312+0000] {processor.py:186} INFO - Started process (PID=1173) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:18.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:03:18.315+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:18.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:18.486+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:18.507+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:18.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:03:18.520+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:18.519+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:03:18.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2024-12-28T21:03:48.675+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:48.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:03:48.678+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:48.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:48.858+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:03:48.878+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:48.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:03:48.890+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:03:48.890+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:03:48.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2024-12-28T21:04:19.052+0000] {processor.py:186} INFO - Started process (PID=1191) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:04:19.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T21:04:19.058+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:04:19.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:04:19.208+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T21:04:19.232+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:04:19.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T21:04:19.248+0000] {logging_mixin.py:190} INFO - [2024-12-28T21:04:19.248+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T21:04:19.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T22:45:19.640+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:19.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:45:19.658+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:19.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:19.997+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:20.053+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:20.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:45:20.080+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:20.080+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:45:20.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.511 seconds
[2024-12-28T22:45:50.319+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:50.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:45:50.322+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:50.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:50.476+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:45:50.501+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:50.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:45:50.516+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:45:50.515+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:45:50.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2024-12-28T22:46:20.683+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:20.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:46:20.686+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:20.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:20.858+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:20.878+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:20.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:46:20.890+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:20.889+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:46:20.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2024-12-28T22:46:51.053+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:51.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:46:51.061+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:51.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:51.229+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:46:51.253+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:51.252+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:46:51.269+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:46:51.269+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:46:51.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.385 seconds
[2024-12-28T22:47:21.579+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:21.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:47:21.582+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:21.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:21.732+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:21.756+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:21.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:47:21.904+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:21.904+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:47:21.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.344 seconds
[2024-12-28T22:47:52.064+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:52.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:47:52.066+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:52.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:52.228+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:47:52.370+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:52.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:47:52.382+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:47:52.382+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:47:52.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.339 seconds
[2024-12-28T22:48:22.548+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:22.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:48:22.552+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:22.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:22.701+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:22.838+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:22.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:48:22.848+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:22.848+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:48:22.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.318 seconds
[2024-12-28T22:48:53.014+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:53.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:48:53.017+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:53.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:53.281+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:48:53.298+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:53.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:48:53.309+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:48:53.308+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:48:53.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.312 seconds
[2024-12-28T22:49:23.472+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:23.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:49:23.475+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:23.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:23.755+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:23.777+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:23.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:49:23.788+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:23.788+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:49:23.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.336 seconds
[2024-12-28T22:49:54.063+0000] {processor.py:186} INFO - Started process (PID=111) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:54.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:49:54.066+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:54.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:54.291+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:49:54.317+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:54.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:49:54.334+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:49:54.334+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:49:54.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.294 seconds
[2024-12-28T22:50:24.504+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:24.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:50:24.508+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:24.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:24.767+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:24.793+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:24.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:50:24.810+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:24.810+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:50:24.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.330 seconds
[2024-12-28T22:50:54.983+0000] {processor.py:186} INFO - Started process (PID=129) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:54.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:50:54.987+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:54.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:55.222+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:50:55.247+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:55.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:50:55.263+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:50:55.263+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:50:55.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.303 seconds
[2024-12-28T22:51:25.429+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:25.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:51:25.431+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:25.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:25.602+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:25.625+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:25.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:51:25.640+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:25.640+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:51:25.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T22:51:55.806+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:55.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:51:55.809+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:55.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:55.966+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:51:55.986+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:55.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:51:55.997+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:51:55.997+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:51:56.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.210 seconds
[2024-12-28T22:52:26.153+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:26.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:52:26.155+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:26.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:26.309+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:26.333+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:26.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:52:26.349+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:26.349+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:52:26.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2024-12-28T22:52:56.509+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:56.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:52:56.512+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:56.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:56.697+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:52:56.720+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:56.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:52:56.736+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:52:56.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:52:56.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.247 seconds
[2024-12-28T22:53:26.898+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:26.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:53:26.901+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:26.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:27.052+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:27.072+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:27.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:53:27.084+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:27.084+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:53:27.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2024-12-28T22:53:57.247+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:57.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:53:57.251+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:57.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:57.404+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:53:57.428+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:57.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:53:57.439+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:53:57.439+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:53:57.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2024-12-28T22:54:27.605+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:27.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:54:27.607+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:27.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:27.786+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:27.809+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:27.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:54:27.820+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:27.820+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:54:27.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2024-12-28T22:54:57.980+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:57.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:54:57.983+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:57.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:58.134+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:54:58.154+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:58.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:54:58.165+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:54:58.165+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:54:58.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T22:55:28.337+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:28.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:55:28.340+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:28.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:28.492+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:28.511+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:28.511+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:55:28.524+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:28.524+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:55:28.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T22:55:58.685+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:58.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:55:58.688+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:58.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:58.839+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:55:58.860+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:58.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:55:58.873+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:55:58.872+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:55:58.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2024-12-28T22:56:29.039+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:29.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:56:29.042+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:29.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:29.212+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:29.237+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:29.236+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:56:29.252+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:29.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:56:29.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2024-12-28T22:56:59.408+0000] {processor.py:186} INFO - Started process (PID=237) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:59.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:56:59.411+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:59.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:59.562+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:56:59.586+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:59.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:56:59.601+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:56:59.601+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:56:59.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2024-12-28T22:57:29.780+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:57:29.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:57:29.784+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:57:29.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:57:29.963+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:57:29.983+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:57:29.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:57:29.995+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:57:29.995+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:57:30.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2024-12-28T22:58:00.149+0000] {processor.py:186} INFO - Started process (PID=261) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:00.150+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:58:00.152+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:00.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:00.302+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:00.326+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:00.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:58:00.343+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:00.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:58:00.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.216 seconds
[2024-12-28T22:58:30.502+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:30.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:58:30.504+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:30.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:30.657+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:58:30.677+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:30.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:58:30.690+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:58:30.690+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:58:30.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.207 seconds
[2024-12-28T22:59:00.848+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:00.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:59:00.852+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:00.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:01.087+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:01.113+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:01.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:59:01.130+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:01.130+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:59:01.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.306 seconds
[2024-12-28T22:59:31.306+0000] {processor.py:186} INFO - Started process (PID=287) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:31.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T22:59:31.308+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:31.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:31.470+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T22:59:31.494+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:31.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T22:59:31.509+0000] {logging_mixin.py:190} INFO - [2024-12-28T22:59:31.509+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T22:59:31.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2024-12-28T23:00:01.670+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:01.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T23:00:01.673+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:01.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:01.894+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:01.923+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:01.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T23:00:01.940+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:01.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T23:00:01.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.295 seconds
[2024-12-28T23:00:32.113+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:32.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T23:00:32.115+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:32.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:32.266+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:00:32.289+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:32.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T23:00:32.301+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:00:32.301+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T23:00:32.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2024-12-28T23:01:02.463+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:02.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T23:01:02.466+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:02.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:02.714+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:02.741+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:02.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T23:01:02.757+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:02.757+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T23:01:02.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.315 seconds
[2024-12-28T23:01:32.916+0000] {processor.py:186} INFO - Started process (PID=323) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:32.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2024-12-28T23:01:32.919+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:32.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:33.078+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2024-12-28T23:01:33.103+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:33.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-28T23:01:33.118+0000] {logging_mixin.py:190} INFO - [2024-12-28T23:01:33.118+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2024-12-28T23:01:33.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
