[2025-01-18T19:09:13.840+0000] {processor.py:186} INFO - Started process (PID=29) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:13.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:09:13.844+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:13.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:14.190+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:14.237+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:14.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:09:14.253+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:14.253+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:09:14.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.443 seconds
[2025-01-18T19:09:44.441+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:44.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:09:44.444+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:44.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:44.671+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:09:44.698+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:44.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:09:44.715+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:09:44.714+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:09:44.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.299 seconds
[2025-01-18T19:10:14.898+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:14.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:10:14.908+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:14.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:15.068+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:15.089+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:15.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:10:15.101+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:15.101+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:10:15.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T19:10:45.276+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:45.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:10:45.283+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:45.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:45.439+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:10:45.458+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:45.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:10:45.471+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:10:45.471+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:10:45.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.334 seconds
[2025-01-18T19:11:15.753+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:15.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:11:15.756+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:15.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:15.904+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:15.925+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:15.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:11:16.060+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:16.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:11:16.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.326 seconds
[2025-01-18T19:11:46.221+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:46.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:11:46.224+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:46.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:46.388+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:11:46.559+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:46.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:11:46.570+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:11:46.569+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:11:46.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.368 seconds
[2025-01-18T19:12:16.738+0000] {processor.py:186} INFO - Started process (PID=83) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:16.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:12:16.742+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:16.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:16.901+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:17.058+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:17.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:12:17.069+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:17.069+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:12:17.083+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.349 seconds
[2025-01-18T19:12:47.244+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:47.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:12:47.247+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:47.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:47.650+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:12:47.696+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:47.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:12:47.711+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:12:47.711+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:12:47.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.493 seconds
[2025-01-18T19:13:17.887+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:17.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:13:17.891+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:17.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:18.189+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:18.210+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:18.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:13:18.225+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:18.225+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:13:18.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.363 seconds
[2025-01-18T19:13:48.394+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:48.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:13:48.397+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:48.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:48.560+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:13:48.581+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:48.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:13:48.594+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:13:48.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:13:48.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2025-01-18T19:14:18.763+0000] {processor.py:186} INFO - Started process (PID=119) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:18.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:14:18.767+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:18.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:18.949+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:18.969+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:18.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:14:18.981+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:18.981+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:14:18.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2025-01-18T19:14:49.150+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:49.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:14:49.154+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:49.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:49.335+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:14:49.356+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:49.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:14:49.367+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:14:49.367+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:14:49.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2025-01-18T19:15:19.539+0000] {processor.py:186} INFO - Started process (PID=137) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:19.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:15:19.543+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:19.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:19.751+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:19.778+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:19.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:15:19.795+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:19.795+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:15:19.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.281 seconds
[2025-01-18T19:15:49.959+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:49.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:15:49.962+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:49.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:50.116+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:15:50.136+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:50.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:15:50.148+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:15:50.148+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:15:50.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2025-01-18T19:16:20.312+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:20.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:16:20.316+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:20.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:20.480+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:20.500+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:20.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:16:20.513+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:20.513+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:16:20.528+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2025-01-18T19:16:50.679+0000] {processor.py:186} INFO - Started process (PID=165) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:50.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:16:50.682+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:50.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:50.837+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:16:50.861+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:50.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:16:50.878+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:16:50.878+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:16:50.896+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.222 seconds
[2025-01-18T19:17:21.047+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:21.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:17:21.050+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:21.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:21.208+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:21.229+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:21.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:17:21.240+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:21.240+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:17:21.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2025-01-18T19:17:51.405+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:51.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:17:51.409+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:51.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:51.572+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:17:51.594+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:51.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:17:51.606+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:17:51.606+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:17:51.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2025-01-18T19:18:21.771+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:21.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:18:21.775+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:21.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:21.946+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:21.970+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:21.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:18:21.982+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:21.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:18:21.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2025-01-18T19:18:52.143+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:52.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:18:52.146+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:52.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:52.319+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:18:52.344+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:52.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:18:52.359+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:18:52.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:18:52.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2025-01-18T19:19:22.535+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:22.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:19:22.537+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:22.537+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:22.693+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:22.715+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:22.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:19:22.728+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:22.728+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:19:22.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2025-01-18T19:19:52.886+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:52.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:19:52.890+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:52.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:53.042+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:19:53.067+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:53.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:19:53.079+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:19:53.079+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:19:53.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2025-01-18T19:20:23.249+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:23.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:20:23.252+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:23.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:23.426+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:23.447+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:23.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:20:23.459+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:23.459+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:20:23.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T19:20:53.627+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:53.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:20:53.630+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:53.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:53.784+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:20:53.803+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:53.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:20:53.815+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:20:53.815+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:20:53.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2025-01-18T19:21:23.982+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:23.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:21:23.984+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:23.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:24.150+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:24.170+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:24.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:21:24.183+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:24.182+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:21:24.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.221 seconds
[2025-01-18T19:21:54.348+0000] {processor.py:186} INFO - Started process (PID=259) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:54.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:21:54.357+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:54.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:54.574+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:21:54.600+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:54.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:21:54.617+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:21:54.617+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:21:54.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.293 seconds
[2025-01-18T19:22:24.794+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:24.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:22:24.796+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:24.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:24.949+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:24.969+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:24.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:22:24.982+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:24.982+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:22:24.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2025-01-18T19:22:55.145+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:55.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:22:55.149+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:55.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:55.311+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:22:55.331+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:55.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:22:55.343+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:22:55.343+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:22:55.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.219 seconds
[2025-01-18T19:23:25.511+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:25.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:23:25.514+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:25.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:25.670+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:25.694+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:25.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:23:25.709+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:25.709+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:23:25.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.220 seconds
[2025-01-18T19:23:55.874+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:55.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:23:55.877+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:55.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:56.027+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:23:56.046+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:56.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:23:56.058+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:23:56.058+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:23:56.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2025-01-18T19:24:26.230+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:26.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:24:26.232+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:26.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:26.389+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:26.409+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:26.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:24:26.421+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:26.421+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:24:26.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.212 seconds
[2025-01-18T19:24:56.582+0000] {processor.py:186} INFO - Started process (PID=313) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:56.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:24:56.593+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:56.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:56.748+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:24:56.772+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:56.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:24:56.789+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:24:56.789+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:24:56.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T19:25:26.956+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:26.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:25:26.959+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:26.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:27.135+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:27.160+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:27.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:25:27.175+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:27.175+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:25:27.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2025-01-18T19:25:57.339+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:57.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:25:57.343+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:57.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:57.495+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:25:57.520+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:57.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:25:57.536+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:25:57.535+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:25:57.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.218 seconds
[2025-01-18T19:26:23.684+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:23.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:26:23.687+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:23.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:23.841+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:23.860+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:23.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:26:23.872+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:23.872+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:26:23.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2025-01-18T19:26:25.760+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:25.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:26:25.762+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:25.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:25.913+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:25.932+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:25.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:26:25.944+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:25.943+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:26:25.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.205 seconds
[2025-01-18T19:26:35.038+0000] {processor.py:186} INFO - Started process (PID=344) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:35.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:26:35.041+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:35.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:35.191+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:26:35.213+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:35.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:26:35.226+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:26:35.226+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:26:35.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2025-01-18T19:27:05.387+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:05.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:27:05.390+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:05.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:05.537+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:05.557+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:05.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:27:05.568+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:05.568+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:27:05.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.201 seconds
[2025-01-18T19:27:35.750+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:35.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:27:35.754+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:35.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:35.901+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:27:35.920+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:35.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:27:35.933+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:27:35.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:27:35.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2025-01-18T19:28:06.119+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:06.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:28:06.121+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:06.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:06.270+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:06.290+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:06.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:28:06.302+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:06.302+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:28:06.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.201 seconds
[2025-01-18T19:28:36.491+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:36.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:28:36.494+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:36.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:36.642+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:28:36.662+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:36.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:28:36.674+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:28:36.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:28:36.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2025-01-18T19:29:06.847+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:06.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:06.851+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:06.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:07.001+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:07.024+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:07.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:07.037+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:07.037+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:07.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2025-01-18T19:29:12.086+0000] {processor.py:186} INFO - Started process (PID=389) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:12.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:12.088+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:12.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:12.237+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:12.256+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:12.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:12.267+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:12.267+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:12.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.201 seconds
[2025-01-18T19:29:13.101+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:13.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:13.103+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:13.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:13.257+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:13.277+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:13.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:13.289+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:13.289+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:13.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.208 seconds
[2025-01-18T19:29:15.323+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:15.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:15.325+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:15.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:15.474+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:15.493+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:15.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:15.505+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:15.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:15.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2025-01-18T19:29:33.491+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:33.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:33.494+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:33.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:33.643+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:33.662+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:33.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:33.674+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:33.674+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:33.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2025-01-18T19:29:34.643+0000] {processor.py:186} INFO - Started process (PID=401) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:34.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:34.646+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:34.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:34.805+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:34.826+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:34.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:34.837+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:34.837+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:34.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.215 seconds
[2025-01-18T19:29:35.882+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:35.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:35.885+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:35.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:36.038+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:36.059+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:36.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:36.070+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:36.070+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:36.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2025-01-18T19:29:56.176+0000] {processor.py:186} INFO - Started process (PID=409) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:56.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:56.180+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:56.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:56.343+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:56.368+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:56.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:29:56.384+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:56.384+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:29:56.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2025-01-18T19:29:58.190+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:58.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:29:58.193+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:58.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:58.199+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:29:58.195+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 50
    executor_memory=f'{ram}g',
                   ^
SyntaxError: positional argument follows keyword argument
[2025-01-18T19:29:58.200+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:29:58.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.035 seconds
[2025-01-18T19:30:00.205+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:00.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:00.208+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:00.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:00.210+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:00.209+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    max
    ^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:00.211+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:00.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:30:02.303+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:02.304+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:02.306+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:02.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:02.309+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:02.308+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    max_res
    ^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:02.309+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:02.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.028 seconds
[2025-01-18T19:30:07.333+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:07.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:07.335+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:07.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:07.338+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:07.337+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    Max_res
    ^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:07.338+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:07.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:30:10.379+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:10.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:10.382+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:10.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:10.385+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:10.384+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    Maxres
    ^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:10.385+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:10.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:30:15.409+0000] {processor.py:186} INFO - Started process (PID=417) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:15.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:15.412+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:15.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:15.415+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:15.414+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    Maxresul
    ^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:15.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:15.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:30:18.451+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:18.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:18.454+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:18.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:18.457+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:18.456+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    maxresul
    ^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:18.457+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:18.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:30:20.472+0000] {processor.py:186} INFO - Started process (PID=419) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:20.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:20.474+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:20.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:20.478+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:20.477+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    maxResul
    ^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:20.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:20.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.029 seconds
[2025-01-18T19:30:23.513+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:23.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:23.515+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:23.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:23.669+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:23.660+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '1g'}
[2025-01-18T19:30:23.670+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:23.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.176 seconds
[2025-01-18T19:30:36.663+0000] {processor.py:186} INFO - Started process (PID=429) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:36.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:36.666+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:36.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:36.669+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:36.668+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 49
    maxResultSize=',
                  ^
SyntaxError: unterminated string literal (detected at line 49)
[2025-01-18T19:30:36.670+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:36.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.029 seconds
[2025-01-18T19:30:41.691+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:41.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:41.694+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:41.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:41.841+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:41.839+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': ''}
[2025-01-18T19:30:41.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:41.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.170 seconds
[2025-01-18T19:30:44.740+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:44.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:44.743+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:44.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:44.887+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:44.885+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g'}
[2025-01-18T19:30:44.888+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:44.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.167 seconds
[2025-01-18T19:30:47.903+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:47.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:47.905+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:47.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:48.052+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:48.050+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 65, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g'}
[2025-01-18T19:30:48.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:48.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.170 seconds
[2025-01-18T19:30:49.943+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:49.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:49.946+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:49.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:49.948+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:49.948+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 50
    mem
    ^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:49.949+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:49.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:30:53.965+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:53.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:53.968+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:53.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:53.971+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:53.970+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 50
    memoryO
    ^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:30:53.972+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:53.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:30:56.009+0000] {processor.py:186} INFO - Started process (PID=441) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:56.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:30:56.011+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:56.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:56.157+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:30:56.154+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 65, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:30:56.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:30:56.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.168 seconds
[2025-01-18T19:31:04.155+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:04.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:04.158+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:04.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:04.161+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:04.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 51
    pack
    ^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:31:04.161+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:04.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:31:06.170+0000] {processor.py:186} INFO - Started process (PID=445) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:06.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:06.173+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:06.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:06.176+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:06.175+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 51
    packages
    ^^^^^^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:31:06.176+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:06.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:31:09.219+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:09.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:09.222+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:09.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:09.225+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:09.224+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 52
    executor_memory=f'{ram}g',
                   ^
SyntaxError: invalid syntax
[2025-01-18T19:31:09.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:09.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.027 seconds
[2025-01-18T19:31:19.272+0000] {processor.py:186} INFO - Started process (PID=447) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:19.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:19.275+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:19.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:19.278+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:19.277+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 51
    packages=''
             ^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:31:19.278+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:19.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:31:21.307+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:21.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:21.309+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:21.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:21.312+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:21.311+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 51
    packages=','
             ^^^^
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-01-18T19:31:21.312+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:21.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T19:31:24.334+0000] {processor.py:186} INFO - Started process (PID=455) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:24.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:24.336+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:24.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:24.483+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:24.481+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:31:24.484+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:24.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.170 seconds
[2025-01-18T19:31:29.388+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:29.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:29.389+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:29.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:29.541+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:29.539+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:31:29.542+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:29.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.173 seconds
[2025-01-18T19:31:59.766+0000] {processor.py:186} INFO - Started process (PID=465) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:59.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:31:59.768+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:59.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:59.915+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:31:59.913+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:31:59.916+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:31:59.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.169 seconds
[2025-01-18T19:32:30.138+0000] {processor.py:186} INFO - Started process (PID=474) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:32:30.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:32:30.139+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:32:30.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:32:30.289+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:32:30.287+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:32:30.290+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:32:30.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.171 seconds
[2025-01-18T19:33:00.474+0000] {processor.py:186} INFO - Started process (PID=483) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:00.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:33:00.477+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:33:00.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:00.622+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:33:00.620+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:33:00.623+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:00.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.167 seconds
[2025-01-18T19:33:30.816+0000] {processor.py:186} INFO - Started process (PID=492) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:30.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:33:30.818+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:33:30.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:30.965+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:33:30.963+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:33:30.966+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:33:30.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.169 seconds
[2025-01-18T19:34:01.162+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:01.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:34:01.165+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:34:01.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:01.311+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:34:01.309+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:34:01.312+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:01.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.171 seconds
[2025-01-18T19:34:31.521+0000] {processor.py:186} INFO - Started process (PID=510) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:31.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:34:31.523+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:34:31.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:31.676+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:34:31.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:34:31.677+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:34:31.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.174 seconds
[2025-01-18T19:35:01.864+0000] {processor.py:186} INFO - Started process (PID=519) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:01.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:35:01.867+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:35:01.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:02.017+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:35:02.014+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:35:02.017+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:02.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.175 seconds
[2025-01-18T19:35:32.212+0000] {processor.py:186} INFO - Started process (PID=528) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:32.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:35:32.214+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:35:32.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:32.400+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:35:32.398+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:35:32.401+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:35:32.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.211 seconds
[2025-01-18T19:36:02.550+0000] {processor.py:186} INFO - Started process (PID=537) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:02.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:36:02.552+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:36:02.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:02.713+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:36:02.711+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:36:02.714+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:02.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.183 seconds
[2025-01-18T19:36:32.905+0000] {processor.py:186} INFO - Started process (PID=546) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:32.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:36:32.907+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:36:32.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:33.052+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:36:33.050+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:36:33.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:36:33.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.166 seconds
[2025-01-18T19:37:03.250+0000] {processor.py:186} INFO - Started process (PID=555) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:03.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:37:03.253+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:37:03.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:03.399+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:37:03.397+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:37:03.400+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:03.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.172 seconds
[2025-01-18T19:37:33.459+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:33.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:37:33.461+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:37:33.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:33.605+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:37:33.603+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:37:33.606+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:37:33.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.165 seconds
[2025-01-18T19:38:03.789+0000] {processor.py:186} INFO - Started process (PID=573) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:03.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:38:03.792+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:38:03.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:03.941+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:38:03.939+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:38:03.942+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:03.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.172 seconds
[2025-01-18T19:38:34.181+0000] {processor.py:186} INFO - Started process (PID=582) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:34.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:38:34.182+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:38:34.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:34.336+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:38:34.334+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:38:34.337+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:38:34.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.176 seconds
[2025-01-18T19:39:04.510+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:04.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:39:04.512+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:39:04.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:04.657+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:39:04.655+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:39:04.658+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:04.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.167 seconds
[2025-01-18T19:39:34.747+0000] {processor.py:186} INFO - Started process (PID=600) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:34.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:39:34.749+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:39:34.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:34.899+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:39:34.896+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:39:34.900+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:39:34.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.174 seconds
[2025-01-18T19:40:04.964+0000] {processor.py:186} INFO - Started process (PID=609) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:04.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:40:04.967+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:40:04.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:05.111+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:40:05.109+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:40:05.112+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:05.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.166 seconds
[2025-01-18T19:40:35.168+0000] {processor.py:186} INFO - Started process (PID=618) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:35.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:40:35.169+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:40:35.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:35.316+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:40:35.313+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:40:35.316+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:40:35.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.167 seconds
[2025-01-18T19:41:05.499+0000] {processor.py:186} INFO - Started process (PID=627) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:05.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:41:05.505+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:05.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:05.651+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:05.649+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:41:05.652+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:05.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.173 seconds
[2025-01-18T19:41:35.887+0000] {processor.py:186} INFO - Started process (PID=636) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:35.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:41:35.889+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:35.889+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:36.035+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:36.033+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'maxResultSize': '12g', 'memoryOverhead': '12g'}
[2025-01-18T19:41:36.036+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:36.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.167 seconds
[2025-01-18T19:41:45.326+0000] {processor.py:186} INFO - Started process (PID=639) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:45.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:41:45.328+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:45.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:45.482+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:45.480+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 66, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 42, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'memoryOverhead': '12g'}
[2025-01-18T19:41:45.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:45.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.176 seconds
[2025-01-18T19:41:47.340+0000] {processor.py:186} INFO - Started process (PID=640) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:47.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:41:47.342+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:47.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:47.493+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:41:47.667+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:47.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:41:47.677+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:41:47.677+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:41:47.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.362 seconds
[2025-01-18T19:42:17.739+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:17.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:42:17.742+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:17.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:17.893+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:17.912+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:17.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:42:17.925+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:17.925+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:42:17.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.206 seconds
[2025-01-18T19:42:48.091+0000] {processor.py:186} INFO - Started process (PID=658) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:48.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:42:48.093+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:48.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:48.242+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:42:48.262+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:48.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:42:48.275+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:42:48.275+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:42:48.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.202 seconds
[2025-01-18T19:43:18.493+0000] {processor.py:186} INFO - Started process (PID=667) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:18.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:43:18.506+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:18.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:18.655+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:18.675+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:18.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:43:18.687+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:18.687+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:43:18.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.213 seconds
[2025-01-18T19:43:48.862+0000] {processor.py:186} INFO - Started process (PID=676) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:48.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:43:48.865+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:48.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:49.014+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:43:49.034+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:49.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:43:49.047+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:43:49.047+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:43:49.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.203 seconds
[2025-01-18T19:44:19.263+0000] {processor.py:186} INFO - Started process (PID=685) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:19.263+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:44:19.266+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:19.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:19.422+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:19.448+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:19.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:44:19.467+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:19.467+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:44:19.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T19:44:49.678+0000] {processor.py:186} INFO - Started process (PID=694) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:49.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:44:49.681+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:49.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:49.892+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:44:49.921+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:49.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:44:49.940+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:44:49.940+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:44:49.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.314 seconds
[2025-01-18T19:45:20.175+0000] {processor.py:186} INFO - Started process (PID=703) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:20.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:45:20.185+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:20.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:20.348+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:20.373+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:20.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:45:20.390+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:20.390+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:45:20.408+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2025-01-18T19:45:50.548+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:50.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:45:50.550+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:50.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:50.698+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:45:50.718+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:50.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:45:50.730+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:45:50.730+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:45:50.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.201 seconds
[2025-01-18T19:46:20.950+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:20.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:46:20.956+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:20.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:21.103+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:21.123+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:21.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:46:21.136+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:21.136+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:46:21.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.209 seconds
[2025-01-18T19:46:30.142+0000] {processor.py:186} INFO - Started process (PID=728) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:30.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:46:30.143+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:30.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:30.293+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:30.313+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:30.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T19:46:30.326+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:30.326+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T19:46:30.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.204 seconds
[2025-01-18T19:46:50.518+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:50.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:46:50.520+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:50.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:50.673+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:46:50.669+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 95, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:46:50.674+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:46:50.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.175 seconds
[2025-01-18T19:47:09.599+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:09.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:09.602+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:09.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:09.747+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:09.746+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 9, in <module>
    CH_IP = os.getenv('CH_IP')
            ^^
NameError: name 'os' is not defined. Did you forget to import 'os'
[2025-01-18T19:47:09.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:09.762+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.168 seconds
[2025-01-18T19:47:19.913+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:19.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:19.915+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:19.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:20.213+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:20.212+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 12, in <module>
    CH_IP = os.getenv('CH_IP')
            ^^
NameError: name 'os' is not defined. Did you forget to import 'os'
[2025-01-18T19:47:20.214+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:20.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.319 seconds
[2025-01-18T19:47:22.059+0000] {processor.py:186} INFO - Started process (PID=742) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:22.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:22.061+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:22.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:22.268+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:22.267+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 13, in <module>
    CH_IP = os.getenv('CH_IP')
            ^^
NameError: name 'os' is not defined. Did you forget to import 'os'
[2025-01-18T19:47:22.269+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:22.282+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T19:47:26.276+0000] {processor.py:186} INFO - Started process (PID=749) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:26.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:26.278+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:26.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:26.505+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:26.503+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:47:26.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:26.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.248 seconds
[2025-01-18T19:47:43.393+0000] {processor.py:186} INFO - Started process (PID=750) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:43.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:43.394+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:43.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:43.602+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:43.600+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 105, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 74, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:47:43.603+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:43.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T19:47:45.652+0000] {processor.py:186} INFO - Started process (PID=752) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:45.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:45.654+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:45.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:45.869+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:45.867+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 106, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 75, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:47:45.870+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:45.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2025-01-18T19:47:48.922+0000] {processor.py:186} INFO - Started process (PID=754) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:48.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:47:48.923+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:48.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:49.135+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:47:49.133+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 107, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 76, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:47:49.136+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:47:49.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T19:48:19.327+0000] {processor.py:186} INFO - Started process (PID=763) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:19.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:48:19.328+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:48:19.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:19.540+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:48:19.538+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 107, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 76, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:48:19.541+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:19.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T19:48:30.377+0000] {processor.py:186} INFO - Started process (PID=770) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:30.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:48:30.380+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:48:30.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:30.586+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:48:30.584+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:48:30.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:48:30.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T19:49:00.820+0000] {processor.py:186} INFO - Started process (PID=780) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:00.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:49:00.822+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:49:00.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:01.027+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:49:01.025+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:49:01.028+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:01.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2025-01-18T19:49:31.222+0000] {processor.py:186} INFO - Started process (PID=789) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:31.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:49:31.224+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:49:31.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:31.432+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:49:31.430+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:49:31.432+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:49:31.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T19:50:01.599+0000] {processor.py:186} INFO - Started process (PID=797) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:01.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:50:01.602+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:50:01.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:01.812+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:50:01.810+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:50:01.813+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:01.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T19:50:32.022+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:32.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:50:32.023+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:50:32.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:32.232+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:50:32.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:50:32.233+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:50:32.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T19:51:02.437+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:02.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:51:02.440+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:51:02.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:02.650+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:51:02.648+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:51:02.650+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:02.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2025-01-18T19:51:32.802+0000] {processor.py:186} INFO - Started process (PID=824) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:32.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:51:32.804+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:51:32.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:33.010+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:51:33.008+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:51:33.011+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:51:33.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T19:52:03.165+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:03.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:52:03.168+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:52:03.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:03.376+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:52:03.374+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:52:03.377+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:03.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T19:52:33.526+0000] {processor.py:186} INFO - Started process (PID=842) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:33.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:52:33.528+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:52:33.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:33.736+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:52:33.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:52:33.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:52:33.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T19:53:03.874+0000] {processor.py:186} INFO - Started process (PID=851) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:03.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:53:03.877+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:53:03.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:04.084+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:53:04.081+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:53:04.084+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:04.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T19:53:34.227+0000] {processor.py:186} INFO - Started process (PID=860) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:34.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:53:34.230+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:53:34.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:34.437+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:53:34.434+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:53:34.437+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:53:34.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T19:54:04.577+0000] {processor.py:186} INFO - Started process (PID=869) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:04.578+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:54:04.578+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:54:04.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:04.789+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:54:04.787+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:54:04.790+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:04.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T19:54:34.938+0000] {processor.py:186} INFO - Started process (PID=878) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:34.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:54:34.941+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:54:34.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:35.157+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:54:35.154+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:54:35.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:54:35.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2025-01-18T19:55:05.279+0000] {processor.py:186} INFO - Started process (PID=887) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:05.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:55:05.281+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:55:05.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:05.485+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:55:05.483+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:55:05.486+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:05.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2025-01-18T19:55:35.633+0000] {processor.py:186} INFO - Started process (PID=896) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:35.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:55:35.636+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:55:35.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:35.843+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:55:35.840+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:55:35.843+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:55:35.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T19:56:05.992+0000] {processor.py:186} INFO - Started process (PID=905) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:05.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:56:05.993+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:56:05.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:06.201+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:56:06.198+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:56:06.201+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:06.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T19:56:36.355+0000] {processor.py:186} INFO - Started process (PID=914) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:36.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:56:36.358+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:56:36.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:36.563+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:56:36.561+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:56:36.563+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:56:36.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T19:57:06.700+0000] {processor.py:186} INFO - Started process (PID=923) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:06.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:57:06.702+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:06.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:06.930+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:06.924+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 12, in <module>
    PYSPARK_CONN_ID
NameError: name 'PYSPARK_CONN_ID' is not defined
[2025-01-18T19:57:06.936+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:06.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.254 seconds
[2025-01-18T19:57:08.855+0000] {processor.py:186} INFO - Started process (PID=924) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:08.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:57:08.856+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:08.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:08.859+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:08.858+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 12
    PYSPARK_CONN_ID = 
                      ^
SyntaxError: invalid syntax
[2025-01-18T19:57:08.860+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:08.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.024 seconds
[2025-01-18T19:57:39.057+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:39.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:57:39.060+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:39.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:39.063+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:39.062+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 12
    PYSPARK_CONN_ID = 
                      ^
SyntaxError: invalid syntax
[2025-01-18T19:57:39.063+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:39.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:57:50.110+0000] {processor.py:186} INFO - Started process (PID=934) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:50.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:57:50.112+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:50.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:50.328+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:57:50.325+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:57:50.328+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:57:50.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2025-01-18T19:58:20.539+0000] {processor.py:186} INFO - Started process (PID=943) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:20.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:58:20.541+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:20.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:20.748+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:20.746+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:58:20.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:20.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T19:58:28.663+0000] {processor.py:186} INFO - Started process (PID=953) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:28.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:58:28.665+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:28.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:28.668+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:28.667+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64
    )
    ^
SyntaxError: positional argument follows keyword argument
[2025-01-18T19:58:28.668+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:28.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:58:30.677+0000] {processor.py:186} INFO - Started process (PID=954) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:30.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:58:30.679+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:30.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:30.682+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:30.681+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64
    )
    ^
SyntaxError: positional argument follows keyword argument
[2025-01-18T19:58:30.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:30.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T19:58:40.756+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:40.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:58:40.758+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:40.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:40.761+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:40.760+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 64
    )
    ^
SyntaxError: positional argument follows keyword argument
[2025-01-18T19:58:40.761+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:40.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.024 seconds
[2025-01-18T19:58:44.785+0000] {processor.py:186} INFO - Started process (PID=956) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:44.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:58:44.787+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:44.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:44.993+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:58:44.991+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 50, in spark_clickhouse_example
    spark_submit_task = SparkSubmitOperator(
                        ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 139, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 949, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to SparkSubmitOperator (task_id: spark_submit_job). Invalid arguments were:
**kwargs: {'PYSPARK_CONN_ID': 'spark'}
[2025-01-18T19:58:44.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:58:45.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T19:59:03.964+0000] {processor.py:186} INFO - Started process (PID=965) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:03.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:59:03.966+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:59:03.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:04.186+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:59:04.183+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:59:04.186+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:04.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.240 seconds
[2025-01-18T19:59:34.320+0000] {processor.py:186} INFO - Started process (PID=974) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:34.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T19:59:34.322+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:59:34.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:34.528+0000] {logging_mixin.py:190} INFO - [2025-01-18T19:59:34.525+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T19:59:34.528+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T19:59:34.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T20:00:04.670+0000] {processor.py:186} INFO - Started process (PID=983) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:04.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:00:04.672+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:00:04.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:04.879+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:00:04.877+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:00:04.879+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:04.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T20:00:35.034+0000] {processor.py:186} INFO - Started process (PID=992) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:35.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:00:35.036+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:00:35.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:35.246+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:00:35.244+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:00:35.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:00:35.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T20:01:05.450+0000] {processor.py:186} INFO - Started process (PID=1001) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:05.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:01:05.452+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:01:05.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:05.658+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:01:05.656+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:01:05.659+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:05.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T20:01:35.831+0000] {processor.py:186} INFO - Started process (PID=1010) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:35.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:01:35.833+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:01:35.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:36.038+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:01:36.036+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:01:36.039+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:01:36.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.225 seconds
[2025-01-18T20:02:06.221+0000] {processor.py:186} INFO - Started process (PID=1019) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:06.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:02:06.223+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:02:06.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:06.429+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:02:06.427+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:02:06.430+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:06.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T20:02:36.580+0000] {processor.py:186} INFO - Started process (PID=1028) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:36.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:02:36.582+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:02:36.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:36.787+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:02:36.785+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:02:36.788+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:02:36.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T20:03:06.993+0000] {processor.py:186} INFO - Started process (PID=1037) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:06.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:03:06.994+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:06.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:07.200+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:07.198+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:03:07.201+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:07.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T20:03:37.364+0000] {processor.py:186} INFO - Started process (PID=1046) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:37.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:03:37.367+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:37.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:37.573+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:37.571+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:03:37.573+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:37.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T20:03:44.598+0000] {processor.py:186} INFO - Started process (PID=1047) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:44.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:03:44.600+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:44.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:44.803+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:44.802+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 54, in spark_clickhouse_example
    conn_id=P,
            ^
NameError: name 'P' is not defined
[2025-01-18T20:03:44.804+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:44.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2025-01-18T20:03:45.639+0000] {processor.py:186} INFO - Started process (PID=1048) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:45.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:03:45.641+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:45.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:45.847+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:03:45.845+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:03:45.847+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:03:45.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T20:04:09.029+0000] {processor.py:186} INFO - Started process (PID=1058) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:09.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:09.030+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:09.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:09.269+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:09.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:09.270+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:09.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.275 seconds
[2025-01-18T20:04:11.329+0000] {processor.py:186} INFO - Started process (PID=1059) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:11.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:11.331+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:11.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:11.542+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:11.540+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:11.543+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:11.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2025-01-18T20:04:14.591+0000] {processor.py:186} INFO - Started process (PID=1060) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:14.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:14.593+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:14.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:14.803+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:14.801+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:14.804+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:14.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2025-01-18T20:04:29.896+0000] {processor.py:186} INFO - Started process (PID=1069) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:29.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:29.898+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:29.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:30.110+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:30.108+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 94, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:30.111+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:30.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2025-01-18T20:04:31.913+0000] {processor.py:186} INFO - Started process (PID=1070) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:31.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:31.914+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:31.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:31.917+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:31.916+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 97
    )
    ^
SyntaxError: unmatched ')'
[2025-01-18T20:04:31.917+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:31.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T20:04:33.966+0000] {processor.py:186} INFO - Started process (PID=1071) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:33.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:33.968+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:33.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:34.183+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:34.180+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:34.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:34.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2025-01-18T20:04:52.281+0000] {processor.py:186} INFO - Started process (PID=1072) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:52.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:52.282+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:52.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:52.504+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:52.502+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 101, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:04:52.505+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:52.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.242 seconds
[2025-01-18T20:04:53.545+0000] {processor.py:186} INFO - Started process (PID=1073) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:53.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:53.547+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:53.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:53.550+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:53.549+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 97
    sc = spark.sparkContext
IndentationError: unexpected indent
[2025-01-18T20:04:53.550+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:53.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:04:57.568+0000] {processor.py:186} INFO - Started process (PID=1080) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:57.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:57.570+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:57.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:57.573+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:57.572+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 97
    sc = spark.sparkContext
IndentationError: unexpected indent
[2025-01-18T20:04:57.574+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:57.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:04:58.605+0000] {processor.py:186} INFO - Started process (PID=1081) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:58.606+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:04:58.607+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:58.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:58.610+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:04:58.609+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 97
    sc = spark.sparkContext
IndentationError: unexpected indent
[2025-01-18T20:04:58.611+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:04:58.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.028 seconds
[2025-01-18T20:05:00.660+0000] {processor.py:186} INFO - Started process (PID=1083) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:00.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:05:00.662+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:00.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:00.878+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:00.876+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:05:00.879+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:00.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2025-01-18T20:05:06.917+0000] {processor.py:186} INFO - Started process (PID=1085) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:06.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:05:06.920+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:06.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:06.923+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:06.922+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 98
    spark.sql("use clickhouse")
IndentationError: unexpected indent
[2025-01-18T20:05:06.924+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:06.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:05:08.943+0000] {processor.py:186} INFO - Started process (PID=1086) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:08.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:05:08.944+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:08.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:09.150+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:09.148+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:05:09.151+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:09.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.227 seconds
[2025-01-18T20:05:39.312+0000] {processor.py:186} INFO - Started process (PID=1095) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:39.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:05:39.314+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:39.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:39.528+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:05:39.525+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:05:39.528+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:05:39.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2025-01-18T20:06:09.688+0000] {processor.py:186} INFO - Started process (PID=1104) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:09.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:06:09.690+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:06:09.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:09.900+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:06:09.898+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:06:09.901+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:09.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2025-01-18T20:06:40.035+0000] {processor.py:186} INFO - Started process (PID=1113) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:40.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:06:40.038+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:06:40.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:40.248+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:06:40.246+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:06:40.249+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:06:40.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.235 seconds
[2025-01-18T20:07:10.398+0000] {processor.py:186} INFO - Started process (PID=1123) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:10.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:07:10.400+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:07:10.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:10.608+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:07:10.606+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:07:10.609+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:10.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T20:07:30.562+0000] {processor.py:186} INFO - Started process (PID=1131) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:30.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:07:30.564+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:07:30.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:30.771+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:07:30.769+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:07:30.772+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:07:30.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T20:08:01.712+0000] {processor.py:186} INFO - Started process (PID=1140) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:01.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:08:01.717+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:01.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:01.928+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:01.926+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:08:01.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:01.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2025-01-18T20:08:14.025+0000] {processor.py:186} INFO - Started process (PID=1142) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:14.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:08:14.026+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:14.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:14.242+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:14.239+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:08:14.242+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:14.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2025-01-18T20:08:16.264+0000] {processor.py:186} INFO - Started process (PID=1143) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:16.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:08:16.265+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:16.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:16.478+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:16.475+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:08:16.478+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:16.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T20:08:46.628+0000] {processor.py:186} INFO - Started process (PID=1152) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:46.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:08:46.630+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:46.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:46.836+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:08:46.834+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:08:46.836+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:08:46.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T20:09:16.982+0000] {processor.py:186} INFO - Started process (PID=1161) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:16.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:16.983+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:16.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:17.189+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:17.187+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 103, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:17.189+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:17.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:09:23.022+0000] {processor.py:186} INFO - Started process (PID=1162) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:23.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:23.024+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:23.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:23.233+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:23.230+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 104, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:23.233+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:23.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.232 seconds
[2025-01-18T20:09:28.279+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:28.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:28.281+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:28.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:28.504+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:28.502+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 105, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:28.505+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:28.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.245 seconds
[2025-01-18T20:09:29.550+0000] {processor.py:186} INFO - Started process (PID=1170) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:29.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:29.551+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:29.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:29.555+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:29.554+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 101
    data = [("Alice", 1), ("Bob", 2), ("Charlie", 3)]
IndentationError: unexpected indent
[2025-01-18T20:09:29.555+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:29.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T20:09:35.654+0000] {processor.py:186} INFO - Started process (PID=1173) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:35.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:35.656+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:35.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:35.659+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:35.658+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 101
    data = [("Alice", 1), ("Bob", 2), ("Charlie", 3)]
IndentationError: unexpected indent
[2025-01-18T20:09:35.660+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:35.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:09:37.669+0000] {processor.py:186} INFO - Started process (PID=1174) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:37.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:37.671+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:37.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:37.674+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:37.673+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 101
    data = [("Alice", 1), ("Bob", 2), ("Charlie", 3)]
IndentationError: unexpected indent
[2025-01-18T20:09:37.675+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:37.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:09:39.712+0000] {processor.py:186} INFO - Started process (PID=1175) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:39.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:39.713+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:39.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:39.929+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:39.927+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:39.930+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:39.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.237 seconds
[2025-01-18T20:09:42.737+0000] {processor.py:186} INFO - Started process (PID=1176) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:42.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:42.738+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:42.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:42.950+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:42.948+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:42.951+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:42.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.233 seconds
[2025-01-18T20:09:44.986+0000] {processor.py:186} INFO - Started process (PID=1177) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:44.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:44.988+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:44.988+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:44.991+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:44.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 112
    df.toPandas().to_csv("/opt/airflow/test/df_test1.csv", index=False)
                                                                       ^
IndentationError: unindent does not match any outer indentation level
[2025-01-18T20:09:44.991+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:45.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.023 seconds
[2025-01-18T20:09:48.011+0000] {processor.py:186} INFO - Started process (PID=1178) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:48.011+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:48.012+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:48.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:48.219+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:48.217+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:48.220+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:48.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T20:09:52.053+0000] {processor.py:186} INFO - Started process (PID=1179) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:52.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:09:52.055+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:52.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:52.261+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:09:52.259+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:09:52.262+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:09:52.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.228 seconds
[2025-01-18T20:10:22.475+0000] {processor.py:186} INFO - Started process (PID=1187) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:22.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:10:22.486+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:10:22.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:22.691+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:10:22.689+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:10:22.692+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:22.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.239 seconds
[2025-01-18T20:10:52.827+0000] {processor.py:186} INFO - Started process (PID=1196) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:52.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:10:52.828+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:10:52.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:53.038+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:10:53.036+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:10:53.038+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:10:53.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.231 seconds
[2025-01-18T20:11:14.137+0000] {processor.py:186} INFO - Started process (PID=1205) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:14.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:14.141+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:14.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:14.145+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:14.144+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    spark_submit_task >> [ch_list_count_rows_start_of_month # >> последовательно, | - паралельное выполнение
                         ^
SyntaxError: '[' was never closed
[2025-01-18T20:11:14.146+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:14.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.030 seconds
[2025-01-18T20:11:16.152+0000] {processor.py:186} INFO - Started process (PID=1206) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:16.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:16.153+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:16.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:16.362+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:16.360+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:16.363+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:16.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:11:18.200+0000] {processor.py:186} INFO - Started process (PID=1207) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:18.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:18.201+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:18.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:18.409+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:18.407+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:18.410+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:18.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T20:11:20.417+0000] {processor.py:186} INFO - Started process (PID=1208) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:20.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:20.418+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:20.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:20.422+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:20.421+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    spark_submit_task ,[ch_list_count_rows_start_of_month # >> последовательно, | - паралельное выполнение
                       ^
SyntaxError: '[' was never closed
[2025-01-18T20:11:20.423+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:20.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:11:24.471+0000] {processor.py:186} INFO - Started process (PID=1209) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:24.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:24.473+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:24.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:24.681+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:24.679+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:24.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:24.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:11:27.495+0000] {processor.py:186} INFO - Started process (PID=1216) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:27.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:27.497+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:27.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:27.500+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:27.499+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    spark_submit_task] ,[ch_list_count_rows_start_of_month] # >> последовательно, | - паралельное выполнение
                     ^
SyntaxError: unmatched ']'
[2025-01-18T20:11:27.501+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:27.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.027 seconds
[2025-01-18T20:11:29.512+0000] {processor.py:186} INFO - Started process (PID=1217) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:29.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:29.514+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:29.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:29.726+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:29.724+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:29.726+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:29.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.234 seconds
[2025-01-18T20:11:31.771+0000] {processor.py:186} INFO - Started process (PID=1218) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:31.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:31.773+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:31.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:32.021+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:32.019+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:32.022+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:32.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.271 seconds
[2025-01-18T20:11:35.802+0000] {processor.py:186} INFO - Started process (PID=1220) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:35.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:35.804+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:35.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:36.011+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:36.009+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:36.012+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:36.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:11:38.061+0000] {processor.py:186} INFO - Started process (PID=1222) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:38.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:38.063+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:38.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:38.067+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:38.066+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task],[ch_list_count_rows_start_of_month]>>  # >> последовательно, | - паралельное выполнение
                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:11:38.067+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:38.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:11:40.076+0000] {processor.py:186} INFO - Started process (PID=1223) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:40.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:40.078+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:40.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:40.081+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:40.081+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task],[ch_list_count_rows_start_of_month] >>  # >> последовательно, | - паралельное выполнение
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:11:40.082+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:40.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T20:11:41.115+0000] {processor.py:186} INFO - Started process (PID=1224) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:41.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:41.116+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:41.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:41.120+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:41.119+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task],[ch_list_count_rows_start_of_month] >>   # >> последовательно, | - паралельное выполнение
                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:11:41.120+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:41.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:11:48.153+0000] {processor.py:186} INFO - Started process (PID=1225) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:48.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:48.156+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:48.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:48.160+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:48.159+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task],[ch_list_count_rows_start_of_month] >>  # >> последовательно, | - паралельное выполнение
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:11:48.160+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:48.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T20:11:50.188+0000] {processor.py:186} INFO - Started process (PID=1226) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:50.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:11:50.190+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:50.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:50.398+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:11:50.396+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:11:50.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:11:50.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:12:05.267+0000] {processor.py:186} INFO - Started process (PID=1233) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:05.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:12:05.269+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:05.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:05.272+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:05.272+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task,[ch_list_count_rows_start_of_month]  # >> последовательно, | - паралельное выполнение
    ^
SyntaxError: '[' was never closed
[2025-01-18T20:12:05.273+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:05.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.027 seconds
[2025-01-18T20:12:07.320+0000] {processor.py:186} INFO - Started process (PID=1235) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:07.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:12:07.322+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:07.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:07.546+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:07.544+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:12:07.547+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:07.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.246 seconds
[2025-01-18T20:12:09.562+0000] {processor.py:186} INFO - Started process (PID=1237) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:09.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:12:09.563+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:09.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:09.772+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:09.770+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:12:09.772+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:09.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:12:15.618+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:15.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:12:15.619+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:15.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:15.623+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:15.622+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task, ch_list_count_rows_start_of_month] >>   # >> последовательно, | - паралельное выполнение
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:12:15.623+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:15.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:12:45.833+0000] {processor.py:186} INFO - Started process (PID=1247) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:45.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:12:45.836+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:45.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:45.840+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:12:45.839+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task, ch_list_count_rows_start_of_month] >>   # >> последовательно, | - паралельное выполнение
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:12:45.840+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:12:45.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.026 seconds
[2025-01-18T20:13:16.064+0000] {processor.py:186} INFO - Started process (PID=1256) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:16.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:13:16.066+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:16.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:16.070+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:16.069+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task, ch_list_count_rows_start_of_month] >>   # >> последовательно, | - паралельное выполнение
                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
SyntaxError: invalid syntax
[2025-01-18T20:13:16.070+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:16.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:13:43.264+0000] {processor.py:186} INFO - Started process (PID=1265) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:43.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:13:43.266+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:43.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:43.476+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:43.474+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:13:43.477+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:43.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.236 seconds
[2025-01-18T20:13:44.422+0000] {processor.py:186} INFO - Started process (PID=1266) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:44.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:13:44.423+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:44.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:44.629+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:44.626+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:13:44.629+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:44.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.226 seconds
[2025-01-18T20:13:58.581+0000] {processor.py:186} INFO - Started process (PID=1273) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:58.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:13:58.583+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:58.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:58.586+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:13:58.585+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 116
    [spark_submit_task, ch_list_count_rows_start_of_month] >> get_files_and_unite)  # >> последовательно, | - паралельное выполнение
                                                                                 ^
SyntaxError: unmatched ')'
[2025-01-18T20:13:58.586+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:13:58.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.024 seconds
[2025-01-18T20:14:04.613+0000] {processor.py:186} INFO - Started process (PID=1274) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:04.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:04.614+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:04.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:04.830+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:04.828+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 119, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:04.831+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:04.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.238 seconds
[2025-01-18T20:14:05.652+0000] {processor.py:186} INFO - Started process (PID=1275) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:05.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:05.653+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:05.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:05.656+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:05.655+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 117
    )  # >> последовательно, | - паралельное выполнение
    ^
SyntaxError: unmatched ')'
[2025-01-18T20:14:05.656+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:05.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.025 seconds
[2025-01-18T20:14:09.715+0000] {processor.py:186} INFO - Started process (PID=1277) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:09.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:09.717+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:09.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:10.045+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:10.043+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 119, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:10.046+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:10.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.355 seconds
[2025-01-18T20:14:11.982+0000] {processor.py:186} INFO - Started process (PID=1279) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:11.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:11.984+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:11.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:12.220+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:12.218+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:12.221+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:12.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.262 seconds
[2025-01-18T20:14:16.118+0000] {processor.py:186} INFO - Started process (PID=1280) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:16.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:16.120+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:16.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:16.401+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:16.399+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:16.402+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:16.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.307 seconds
[2025-01-18T20:14:17.286+0000] {processor.py:186} INFO - Started process (PID=1281) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:17.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:17.287+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:17.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:17.496+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:17.494+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:17.497+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:17.511+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.230 seconds
[2025-01-18T20:14:47.665+0000] {processor.py:186} INFO - Started process (PID=1290) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:47.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:14:47.666+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:47.666+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:47.873+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:14:47.871+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 118, in <module>
    spark_clickhouse_example()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 4307, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 72, in spark_clickhouse_example
    @task.pyspark(
     ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/__init__.py", line 82, in __getattr__
    return decorators[name]
           ~~~~~~~~~~^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers_manager.py", line 122, in __getitem__
    value = value()
            ^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/apache/spark/decorators/pyspark.py", line 26, in <module>
    from airflow.providers.common.compat.standard.operators import PythonOperator
ModuleNotFoundError: No module named 'airflow.providers.common.compat.standard'
[2025-01-18T20:14:47.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:14:47.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.229 seconds
[2025-01-18T20:16:57.626+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:16:57.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:16:57.634+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:16:57.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:16:58.195+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:16:58.424+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:16:58.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:16:58.438+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:16:58.437+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:16:58.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.848 seconds
[2025-01-18T20:17:28.626+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:17:28.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:17:28.629+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:17:28.629+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:17:29.075+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:17:29.100+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:17:29.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:17:29.112+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:17:29.112+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:17:29.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.509 seconds
[2025-01-18T20:17:59.828+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:17:59.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:17:59.849+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:17:59.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:18:00.199+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:18:00.217+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:18:00.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:18:00.228+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:18:00.228+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:18:00.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.418 seconds
[2025-01-18T20:18:30.350+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:18:30.351+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:18:30.352+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:18:30.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:18:30.707+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:18:30.726+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:18:30.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:18:30.736+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:18:30.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:18:30.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.405 seconds
[2025-01-18T20:19:01.573+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:01.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:19:01.596+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:01.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:01.936+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:01.954+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:01.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:19:01.964+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:01.964+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:19:01.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.412 seconds
[2025-01-18T20:19:58.359+0000] {processor.py:186} INFO - Started process (PID=31) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:58.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:19:58.363+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:58.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:58.900+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:19:58.925+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:58.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:19:58.939+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:19:58.939+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:19:58.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.607 seconds
[2025-01-18T20:20:29.094+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:29.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:20:29.097+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:20:29.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:29.476+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:29.494+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:20:29.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:20:29.505+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:20:29.505+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:20:29.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.429 seconds
[2025-01-18T20:20:59.635+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:59.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:20:59.637+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:20:59.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:59.979+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:20:59.997+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:20:59.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:21:00.008+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:21:00.008+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:21:00.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.392 seconds
[2025-01-18T20:21:30.062+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:21:30.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:21:30.065+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:21:30.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:21:30.398+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:21:30.415+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:21:30.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:21:30.427+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:21:30.427+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:21:30.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.382 seconds
[2025-01-18T20:22:00.589+0000] {processor.py:186} INFO - Started process (PID=71) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:22:00.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:22:00.592+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:22:00.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:22:00.936+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:22:00.955+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:22:00.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:22:00.966+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:22:00.965+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:22:00.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.396 seconds
[2025-01-18T20:23:00.803+0000] {processor.py:186} INFO - Started process (PID=30) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:00.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:23:00.807+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:00.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:01.591+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:01.623+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:01.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:23:01.639+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:01.639+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:23:01.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.862 seconds
[2025-01-18T20:23:31.830+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:31.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:23:31.835+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:31.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:32.367+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:23:32.387+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:32.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:23:32.404+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:23:32.404+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:23:32.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.598 seconds
[2025-01-18T20:24:02.774+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:02.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:24:02.782+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:02.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:03.207+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:03.241+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:03.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:24:03.252+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:03.252+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:24:03.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.498 seconds
[2025-01-18T20:24:33.982+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:33.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:24:33.991+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:33.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:34.323+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:24:34.340+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:34.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:24:34.351+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:24:34.351+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:24:34.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.387 seconds
[2025-01-18T20:25:04.513+0000] {processor.py:186} INFO - Started process (PID=73) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:04.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:25:04.521+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:04.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:04.876+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:04.894+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:04.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:25:04.905+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:04.905+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:25:04.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.411 seconds
[2025-01-18T20:25:35.040+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:35.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:25:35.042+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:35.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:35.392+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:25:35.410+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:35.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:25:35.420+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:25:35.420+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:25:35.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.399 seconds
[2025-01-18T20:26:05.544+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:05.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:26:05.546+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:05.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:05.899+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:05.918+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:05.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:26:05.930+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:05.930+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:26:05.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.405 seconds
[2025-01-18T20:26:36.184+0000] {processor.py:186} INFO - Started process (PID=101) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:36.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:26:36.187+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:36.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:36.552+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:26:36.577+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:36.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:26:36.589+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:26:36.589+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:26:36.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.703 seconds
[2025-01-18T20:27:07.262+0000] {processor.py:186} INFO - Started process (PID=117) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:07.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:27:07.276+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:07.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:07.618+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:07.636+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:07.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:27:07.647+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:07.647+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:27:07.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.404 seconds
[2025-01-18T20:27:37.844+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:37.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:27:37.846+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:37.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:38.188+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:27:38.206+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:38.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:27:38.217+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:27:38.217+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:27:38.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.393 seconds
[2025-01-18T20:28:08.545+0000] {processor.py:186} INFO - Started process (PID=135) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:08.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:28:08.547+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:08.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:08.903+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:08.922+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:08.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:28:08.933+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:08.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:28:08.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.406 seconds
[2025-01-18T20:28:39.058+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:39.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:28:39.061+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:39.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:39.401+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:28:39.426+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:39.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:28:39.442+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:28:39.442+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:28:39.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.408 seconds
[2025-01-18T20:29:09.548+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:09.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:29:09.551+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:09.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:09.957+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:09.983+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:09.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:29:09.999+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:09.998+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:29:10.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.475 seconds
[2025-01-18T20:29:40.144+0000] {processor.py:186} INFO - Started process (PID=161) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:40.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:29:40.154+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:40.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:40.513+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:29:40.531+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:40.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:29:40.542+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:29:40.542+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:29:40.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.418 seconds
[2025-01-18T20:30:10.809+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:10.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:30:10.811+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:10.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:11.151+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:11.168+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:11.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:30:11.179+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:11.179+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:30:11.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.389 seconds
[2025-01-18T20:30:41.317+0000] {processor.py:186} INFO - Started process (PID=179) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:41.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:30:41.320+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:41.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:41.660+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:30:41.677+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:41.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:30:41.689+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:30:41.689+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:30:41.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.389 seconds
[2025-01-18T20:31:11.833+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:11.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:31:11.836+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:11.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:12.161+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:12.180+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:12.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:31:12.190+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:12.190+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:31:12.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.376 seconds
[2025-01-18T20:31:42.325+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:42.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:31:42.328+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:42.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:42.667+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:31:42.685+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:42.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:31:42.696+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:31:42.696+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:31:42.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.389 seconds
[2025-01-18T20:32:12.848+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:12.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:32:12.850+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:12.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:13.182+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:13.199+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:13.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:32:13.210+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:13.210+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:32:13.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.380 seconds
[2025-01-18T20:32:44.060+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:44.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:32:44.070+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:44.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:44.286+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:32:44.306+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:44.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:32:44.319+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:32:44.319+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:32:44.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.277 seconds
[2025-01-18T20:33:14.445+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:14.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:33:14.447+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:14.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:14.663+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:14.684+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:14.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:33:14.696+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:14.695+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:33:14.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.270 seconds
[2025-01-18T20:33:44.814+0000] {processor.py:186} INFO - Started process (PID=233) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:44.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:33:44.817+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:44.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:45.028+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:33:45.048+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:45.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:33:45.060+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:33:45.060+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:33:45.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.265 seconds
[2025-01-18T20:34:15.190+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:15.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:34:15.193+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:15.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:15.407+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:15.427+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:15.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:34:15.439+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:15.438+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:34:15.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.267 seconds
[2025-01-18T20:34:45.561+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:45.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:34:45.564+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:45.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:45.773+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:34:45.793+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:45.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:34:45.805+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:34:45.805+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:34:45.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.265 seconds
[2025-01-18T20:35:15.938+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:15.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:35:15.941+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:15.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:16.151+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:16.171+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:16.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:35:16.184+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:16.184+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:35:16.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.264 seconds
[2025-01-18T20:35:46.305+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:46.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:35:46.309+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:46.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:46.544+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:35:46.565+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:46.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:35:46.577+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:35:46.577+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:35:46.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.291 seconds
[2025-01-18T20:36:16.772+0000] {processor.py:186} INFO - Started process (PID=279) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:16.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:36:16.774+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:16.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:16.989+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:17.010+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:17.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:36:17.022+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:17.022+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:36:17.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.271 seconds
[2025-01-18T20:36:47.152+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:47.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:36:47.156+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:47.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:47.376+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:36:47.397+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:47.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:36:47.408+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:36:47.408+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:36:47.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.276 seconds
[2025-01-18T20:37:17.521+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:17.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:37:17.524+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:17.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:17.737+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:17.758+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:17.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:37:17.771+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:17.771+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:37:17.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.270 seconds
[2025-01-18T20:37:47.941+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:47.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:37:47.944+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:47.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:48.171+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:37:48.193+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:48.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:37:48.205+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:37:48.205+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:37:48.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.284 seconds
[2025-01-18T20:38:18.334+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:18.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:38:18.338+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:18.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:18.558+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:18.582+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:18.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:38:18.595+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:18.594+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:38:18.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.280 seconds
[2025-01-18T20:38:48.723+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:48.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:38:48.725+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:48.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:48.938+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:38:48.959+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:48.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:38:48.970+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:38:48.970+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:38:48.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.266 seconds
[2025-01-18T20:39:19.113+0000] {processor.py:186} INFO - Started process (PID=333) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:19.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:39:19.116+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:19.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:19.327+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:19.347+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:19.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:39:19.359+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:19.359+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:39:19.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.266 seconds
[2025-01-18T20:39:49.482+0000] {processor.py:186} INFO - Started process (PID=342) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:49.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:39:49.484+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:49.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:49.703+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:39:49.723+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:49.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:39:49.736+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:39:49.736+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:39:49.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.273 seconds
[2025-01-18T20:40:19.855+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:19.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:40:19.858+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:19.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:20.068+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:20.089+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:20.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:40:20.100+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:20.100+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:40:20.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.264 seconds
[2025-01-18T20:40:50.224+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:50.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:40:50.226+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:50.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:50.436+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:40:50.457+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:50.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:40:50.469+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:40:50.469+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:40:50.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.264 seconds
[2025-01-18T20:41:12.481+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:12.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:41:12.487+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:12.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:12.492+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:12.491+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_spark_clickhouse.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_spark_clickhouse.py", line 101
    data = [("Alice", 1), ("Bob", 2), ("Charlie", 3)]
IndentationError: unexpected indent
[2025-01-18T20:41:12.492+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:12.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.045 seconds
[2025-01-18T20:41:14.497+0000] {processor.py:186} INFO - Started process (PID=367) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:14.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:41:14.501+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:14.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:14.745+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:14.769+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:14.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:41:14.782+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:14.781+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:41:14.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.309 seconds
[2025-01-18T20:41:44.896+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:44.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:41:44.906+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:44.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:45.120+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:41:45.141+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:45.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:41:45.153+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:41:45.153+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:41:45.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.278 seconds
[2025-01-18T20:42:15.265+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:15.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:42:15.267+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:15.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:15.494+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:15.520+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:15.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:42:15.537+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:15.537+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:42:15.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.296 seconds
[2025-01-18T20:42:45.684+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:45.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_spark_clickhouse.py for tasks to queue
[2025-01-18T20:42:45.686+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:45.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:45.900+0000] {processor.py:925} INFO - DAG(s) 'spark_clickhouse_example' retrieved from /opt/airflow/dags/test_spark_clickhouse.py
[2025-01-18T20:42:45.921+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:45.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-01-18T20:42:45.933+0000] {logging_mixin.py:190} INFO - [2025-01-18T20:42:45.933+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_clickhouse_example to None, run_after=None
[2025-01-18T20:42:45.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_spark_clickhouse.py took 0.269 seconds
